
Original sample:

{"has_bug": true, "bug_kind": 1, "bug_kind_name": "VARIABLE_MISUSE", "source_tokens": ["#NEWLINE#", "def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "#INDENT#", "'Determines if source_refs contains a valid list of source references.\\n\\n  Args:\\n    source_refs: A multi-line string containing one source reference per line.\\n\\n  Raises:\\n    ValidationError: when the reference is malformed.\\n  '", "#NEWLINE#", "if", "(", "len", "(", "ref", ")", ">", "SOURCE_REFERENCES_MAX_SIZE", ")", ":", "#NEWLINE#", "#INDENT#", "raise", "validation", ".", "ValidationError", "(", "(", "'Total source reference(s) size exceeds the limit: %d > %d'", "%", "(", "len", "(", "source_refs", ")", ",", "SOURCE_REFERENCES_MAX_SIZE", ")", ")", ")", "#NEWLINE#", "#UNINDENT#", "for", "ref", "in", "source_refs", ".", "splitlines", "(", ")", ":", "#NEWLINE#", "#INDENT#", "ValidateSourceReference", "(", "ref", ".", "strip", "(", ")", ")"], "error_location": [13], "repair_targets": [2, 32, 44], "repair_candidates": [13, 42, 54, 2, 32, 44], "provenances": [{"datasetProvenance": {"datasetName": "ETHPy150Open", "filepath": "GoogleCloudPlatform/python-compat-runtime/appengine-compat/exported_appengine_sdk/google/appengine/api/appinfo.py", "license": "apache-2.0", "note": "license: bigquery_api"}}], "txt_file": "eval__VARIABLE_MISUSE__SStuB.txt-00000-of-00300", "js_count": 1088, "results": {"model": "rnn", "prob": {"loc": [[1.850308217399288e-05, 4.87595346043701e-11, 1.1233531882481884e-09, 1.1027959795351094e-10, 3.964785531135329e-12, 5.6049779401101674e-11, 1.46261440459039e-11, 8.073539059516577e-11, 1.289228634959727e-07, 1.0131175412486648e-11, 1.0406439265864265e-08, 3.0006924589542905e-07, 2.339961184816275e-07, 0.9999783039093018, 4.2061959248940184e-08, 1.1969207569517692e-10, 1.6168758554258034e-09, 4.3128656895818906e-11, 9.585406773870986e-11, 6.009356345870742e-10, 1.7045161115891716e-10, 1.2872523880158582e-10, 1.59342997130274e-10, 8.878657531408152e-11, 1.6271507795664886e-12, 3.0000353330034146e-12, 7.43977449091382e-12, 8.319610972362668e-11, 1.0239787533519729e-12, 1.1298593310948846e-10, 3.6910936113132564e-11, 2.8791758907575904e-11, 2.533876795496326e-06, 1.3804506149295293e-11, 1.5948330980494752e-12, 1.2427930906611095e-10, 5.516372948710657e-12, 2.9511264959536376e-11, 7.964213316613566e-11, 9.935799960558711e-10, 5.826448656875982e-09, 4.792088600935607e-11, 4.505238543339729e-11, 1.4594717101523713e-10, 4.515634977053651e-09, 8.681490248907409e-11, 3.397851661493534e-12, 1.433963711661157e-11, 1.1118296283640916e-09, 4.925494040408651e-11, 7.901662657516795e-11, 3.6220343131027066e-12, 2.4411850579192373e-12, 1.5363250602251632e-11, 1.6388771451048e-09, 4.938454593178543e-12, 9.04310307192624e-12, 3.8885911851638255e-11, 4.026383226829466e-09, 2.1903739239048647e-11]], "pointer": [[0.0, 0.0, 0.9993765950202942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.520599188457709e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0005337263573892415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.294635724974796e-05, 0.0, 7.387075129372533e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.762977030419279e-06, 0.0, 0.0, 0.0, 0.0, 0.0]], "target": [0.9999176859855652]}, "loss": [2.1934269170742482e-05, 8.231740503106266e-05], "acc": [0.0, 1.0, 1.0, 1.0]}}


Trace of simplified code(s):

{"result": {"time": "2021-02-11 09:52:36.378515", "n_pass": [1, 1, 1], "n_token": 60, "loss": [2.1934269170742482e-05, 8.231740503106266e-05], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "#INDENT#", "'Determines if source_refs contains a valid list of source references.\\n\\n  Args:\\n    source_refs: A multi-line string containing one source reference per line.\\n\\n  Raises:\\n    ValidationError: when the reference is malformed.\\n  '", "#NEWLINE#", "if", "(", "len", "(", "ref", ")", ">", "SOURCE_REFERENCES_MAX_SIZE", ")", ":", "#NEWLINE#", "#INDENT#", "raise", "validation", ".", "ValidationError", "(", "(", "'Total source reference(s) size exceeds the limit: %d > %d'", "%", "(", "len", "(", "source_refs", ")", ",", "SOURCE_REFERENCES_MAX_SIZE", ")", ")", ")", "#NEWLINE#", "#UNINDENT#", "for", "ref", "in", "source_refs", ".", "splitlines", "(", ")", ":", "#NEWLINE#", "#INDENT#", "ValidateSourceReference", "(", "ref", ".", "strip", "(", ")", ")"]}}
{"position": {"error_location": 13, "repair_targets": [2, 32, 44], "repair_candidates": [13, 42, 54, 2, 32, 44]}}
{"prediction": {"error_location": 0.9999783039093018, "repair_targets": [0.9993765950202942, 0.0005337263573892415, 7.387075129372533e-06], "repair_candidates": [0.9993765950202942, 5.520599188457709e-06, 0.0005337263573892415, 7.294635724974796e-05, 7.387075129372533e-06, 3.762977030419279e-06], "target_probs": 0.9999176859855652}}


{"result": {"time": "2021-02-11 09:52:36.450020", "n_pass": [9, 2, 2], "n_token": 45, "loss": [0.000705470098182559, 0.0006079137092456222], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "#INDENT#", "'Determines if source_refs contains a valid list of source references.\\n\\n  Args:\\n    source_refs: A multi-line string containing one source reference per line.\\n\\n  Raises:\\n    ValidationError: when the reference is malformed.\\n  '", "#NEWLINE#", "if", "(", "len", "(", "ref", ")", "len", "(", "source_refs", ")", ",", "SOURCE_REFERENCES_MAX_SIZE", ")", ")", ")", "#NEWLINE#", "#UNINDENT#", "for", "ref", "in", "source_refs", ".", "splitlines", "(", ")", ":", "#NEWLINE#", "#INDENT#", "ValidateSourceReference", "(", "ref", ".", "strip", "(", ")", ")"]}}
{"position": {"error_location": 13, "repair_targets": [2, 17, 29], "repair_candidates": [13, 27, 39, 2, 17, 29]}}
{"prediction": {"error_location": 0.9992945194244385, "repair_targets": [0.9991201758384705, 0.0002436612412566319, 2.845985181920696e-05], "repair_candidates": [0.9991201758384705, 7.290861503861379e-06, 0.0002436612412566319, 0.0005809944123029709, 2.845985181920696e-05, 1.9358612917130813e-05], "target_probs": 0.9993922710418701}}


{"result": {"time": "2021-02-11 09:52:36.520331", "n_pass": [38, 3, 3], "n_token": 41, "loss": [0.0014869834994897246, 0.038181234151124954], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "#INDENT#", "'Determines if source_refs contains a valid list of source references.\\n\\n  Args:\\n    source_refs: A multi-line string containing one source reference per line.\\n\\n  Raises:\\n    ValidationError: when the reference is malformed.\\n  '", "#NEWLINE#", "if", "(", "len", "(", "ref", ")", "len", "(", "source_refs", ")", ",", "SOURCE_REFERENCES_MAX_SIZE", "#UNINDENT#", "for", "ref", "in", "source_refs", ".", "splitlines", "(", ")", ":", "#NEWLINE#", "#INDENT#", "ValidateSourceReference", "(", "ref", ".", "strip", "(", ")", ")"]}}
{"position": {"error_location": 13, "repair_targets": [2, 17, 25], "repair_candidates": [13, 23, 35, 2, 17, 25]}}
{"prediction": {"error_location": 0.9985138773918152, "repair_targets": [0.9616691470146179, 0.0003721903485711664, 0.0004971554153598845], "repair_candidates": [0.9616691470146179, 2.3056889403960668e-05, 0.0003721903485711664, 0.03741118311882019, 0.0004971554153598845, 2.7298212444293313e-05], "target_probs": 0.962538480758667}}


{"result": {"time": "2021-02-11 09:52:36.587858", "n_pass": [40, 4, 4], "n_token": 37, "loss": [0.001261987374164164, 0.054729606956243515], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "#INDENT#", "'Determines if source_refs contains a valid list of source references.\\n\\n  Args:\\n    source_refs: A multi-line string containing one source reference per line.\\n\\n  Raises:\\n    ValidationError: when the reference is malformed.\\n  '", "#NEWLINE#", "if", "(", "len", "(", "ref", ")", "len", "(", "source_refs", ")", ",", "SOURCE_REFERENCES_MAX_SIZE", "#UNINDENT#", "for", "ref", "in", "source_refs", ".", "splitlines", "(", "ValidateSourceReference", "(", "ref", ".", "strip", "(", ")", ")"]}}
{"position": {"error_location": 13, "repair_targets": [2, 17, 25], "repair_candidates": [13, 23, 31, 2, 17, 25]}}
{"prediction": {"error_location": 0.9987388253211975, "repair_targets": [0.94521164894104, 0.0006156089948490262, 0.0009138695895671844], "repair_candidates": [0.94521164894104, 1.9315984900458716e-05, 0.0006156089948490262, 0.05323449522256851, 0.0009138695895671844, 5.093995696370257e-06], "target_probs": 0.9467411041259766}}


{"result": {"time": "2021-02-11 09:52:36.655357", "n_pass": [42, 5, 5], "n_token": 33, "loss": [0.0030519834253937006, 0.08272343128919601], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "#INDENT#", "'Determines if source_refs contains a valid list of source references.\\n\\n  Args:\\n    source_refs: A multi-line string containing one source reference per line.\\n\\n  Raises:\\n    ValidationError: when the reference is malformed.\\n  '", "#NEWLINE#", "if", "(", "len", "(", "ref", ")", "len", "(", "source_refs", ")", ",", "SOURCE_REFERENCES_MAX_SIZE", "#UNINDENT#", "for", "ref", "in", "source_refs", ".", "splitlines", "(", "ValidateSourceReference", "(", "ref", "."]}}
{"position": {"error_location": 13, "repair_targets": [2, 17, 25], "repair_candidates": [13, 23, 31, 2, 17, 25]}}
{"prediction": {"error_location": 0.9969526529312134, "repair_targets": [0.9149691462516785, 0.004871093202382326, 0.000765473407227546], "repair_candidates": [0.9149691462516785, 5.6631852203281596e-05, 0.004871093202382326, 0.079326331615448, 0.000765473407227546, 1.1358529263816308e-05], "target_probs": 0.9206057190895081}}


{"result": {"time": "2021-02-11 09:52:36.782210", "n_pass": [45, 7, 6], "n_token": 30, "loss": [0.01286233775317669, 0.4476848244667053], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "if", "(", "len", "(", "ref", ")", "len", "(", "source_refs", ")", ",", "SOURCE_REFERENCES_MAX_SIZE", "#UNINDENT#", "for", "ref", "in", "source_refs", ".", "splitlines", "(", "ValidateSourceReference", "(", "ref", "."]}}
{"position": {"error_location": 10, "repair_targets": [2, 14, 22], "repair_candidates": [10, 20, 28, 2, 14, 22]}}
{"prediction": {"error_location": 0.9872199296951294, "repair_targets": [0.6077303886413574, 0.02962462604045868, 0.0017510621109977365], "repair_candidates": [0.6077303886413574, 0.0006703154067508876, 0.02962462604045868, 0.36018645763397217, 0.0017510621109977365, 3.7165398680372164e-05], "target_probs": 0.6391060948371887}}


{"result": {"time": "2021-02-11 09:52:36.969335", "n_pass": [70, 10, 7], "n_token": 28, "loss": [0.05121971666812897, 0.5625518560409546], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "len", "(", "ref", ")", "len", "(", "source_refs", ")", ",", "SOURCE_REFERENCES_MAX_SIZE", "#UNINDENT#", "for", "ref", "in", "source_refs", ".", "splitlines", "(", "ValidateSourceReference", "(", "ref", "."]}}
{"position": {"error_location": 8, "repair_targets": [2, 12, 20], "repair_candidates": [8, 18, 26, 2, 12, 20]}}
{"prediction": {"error_location": 0.9500700235366821, "repair_targets": [0.5487948060035706, 0.01959919184446335, 0.0013593017356470227], "repair_candidates": [0.5487948060035706, 0.0012930508237332106, 0.01959919184446335, 0.42891812324523926, 0.0013593017356470227, 3.5490615118760616e-05], "target_probs": 0.5697532892227173}}


{"result": {"time": "2021-02-11 09:52:37.033104", "n_pass": [72, 11, 8], "n_token": 26, "loss": [0.004781241994351149, 0.14031556248664856], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "len", "(", "ref", ")", "source_refs", ")", ",", "SOURCE_REFERENCES_MAX_SIZE", "#UNINDENT#", "for", "ref", "in", "source_refs", ".", "splitlines", "(", "ValidateSourceReference", "(", "ref", "."]}}
{"position": {"error_location": 8, "repair_targets": [2, 10, 18], "repair_candidates": [8, 16, 24, 2, 10, 18]}}
{"prediction": {"error_location": 0.9952301979064941, "repair_targets": [0.7892075181007385, 0.07878782600164413, 0.0010886404197663069], "repair_candidates": [0.7892075181007385, 0.0012424035230651498, 0.07878782600164413, 0.12963904440402985, 0.0010886404197663069, 3.45939515682403e-05], "target_probs": 0.8690839409828186}}


{"result": {"time": "2021-02-11 09:52:37.093238", "n_pass": [74, 12, 9], "n_token": 24, "loss": [0.0079257283359766, 0.07253620773553848], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "len", "(", "ref", ")", "source_refs", ")", "#UNINDENT#", "for", "ref", "in", "source_refs", ".", "splitlines", "(", "ValidateSourceReference", "(", "ref", "."]}}
{"position": {"error_location": 8, "repair_targets": [2, 10, 16], "repair_candidates": [8, 14, 22, 2, 10, 16]}}
{"prediction": {"error_location": 0.9921056032180786, "repair_targets": [0.8534416556358337, 0.07628389447927475, 0.0003065536729991436], "repair_candidates": [0.8534416556358337, 0.0010090679861605167, 0.07628389447927475, 0.06890662759542465, 0.0003065536729991436, 5.214924021856859e-05], "target_probs": 0.9300320744514465}}


{"result": {"time": "2021-02-11 09:52:37.152627", "n_pass": [75, 13, 10], "n_token": 22, "loss": [0.020386330783367157, 0.01833752542734146], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "len", "(", "ref", ")", "source_refs", ")", "ref", "in", "source_refs", ".", "splitlines", "(", "ValidateSourceReference", "(", "ref", "."]}}
{"position": {"error_location": 8, "repair_targets": [2, 10, 14], "repair_candidates": [8, 12, 20, 2, 10, 14]}}
{"prediction": {"error_location": 0.9798200726509094, "repair_targets": [0.7776767611503601, 0.20336970686912537, 0.0007831350085325539], "repair_candidates": [0.7776767611503601, 0.0032506014686077833, 0.20336970686912537, 0.014871951192617416, 0.0007831350085325539, 4.7790661483304575e-05], "target_probs": 0.9818295836448669}}


{"result": {"time": "2021-02-11 09:52:37.211153", "n_pass": [78, 14, 11], "n_token": 20, "loss": [0.01590670272707939, 0.004740848671644926], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "len", "(", "ref", ")", "source_refs", ")", "ref", "in", "source_refs", ".", "ValidateSourceReference", "(", "ref", "."]}}
{"position": {"error_location": 8, "repair_targets": [2, 10, 14], "repair_candidates": [8, 12, 18, 2, 10, 14]}}
{"prediction": {"error_location": 0.9842191338539124, "repair_targets": [0.7760562300682068, 0.21900498867034912, 0.0002091412607114762], "repair_candidates": [0.7760562300682068, 0.00033671624260023236, 0.21900498867034912, 0.004364564549177885, 0.0002091412607114762, 2.8381224183249287e-05], "target_probs": 0.9952703714370728}}


{"result": {"time": "2021-02-11 09:52:37.326757", "n_pass": [81, 16, 12], "n_token": 19, "loss": [0.6701204776763916, 0.05260031670331955], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "len", "(", "ref", ")", "source_refs", ")", "ref", "in", "source_refs", ".", "ValidateSourceReference", "(", "ref", "."]}}
{"position": {"error_location": 7, "repair_targets": [1, 9, 13], "repair_candidates": [7, 11, 17, 1, 9, 13]}}
{"prediction": {"error_location": 0.5116469264030457, "repair_targets": [0.8183566927909851, 0.12976454198360443, 0.0006378882681019604], "repair_candidates": [0.8183566927909851, 0.01858840137720108, 0.12976454198360443, 0.032255493104457855, 0.0006378882681019604, 0.00039702211506664753], "target_probs": 0.948759138584137}}


{"result": {"time": "2021-02-11 09:52:37.957296", "n_pass": [119, 27, 13], "n_token": 18, "loss": [0.7572488784790039, 0.012821020558476448], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "len", "(", "ref", ")", "source_refs", "ref", "in", "source_refs", ".", "ValidateSourceReference", "(", "ref", "."]}}
{"position": {"error_location": 7, "repair_targets": [1, 9, 12], "repair_candidates": [7, 10, 16, 1, 9, 12]}}
{"prediction": {"error_location": 0.46895483136177063, "repair_targets": [0.8271301984786987, 0.15879859030246735, 0.0013320202706381679], "repair_candidates": [0.8271301984786987, 0.008340663276612759, 0.15879859030246735, 0.003610010724514723, 0.0013320202706381679, 0.0007884773658588529], "target_probs": 0.9872608184814453}}


{"result": {"time": "2021-02-11 09:52:38.013923", "n_pass": [121, 28, 14], "n_token": 17, "loss": [0.1906888633966446, 0.015056077390909195], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "len", "(", "ref", ")", "source_refs", "ref", "source_refs", ".", "ValidateSourceReference", "(", "ref", "."]}}
{"position": {"error_location": 7, "repair_targets": [1, 9, 11], "repair_candidates": [7, 10, 15, 1, 9, 11]}}
{"prediction": {"error_location": 0.826389729976654, "repair_targets": [0.9397644400596619, 0.044638730585575104, 0.0006535524735227227], "repair_candidates": [0.9397644400596619, 0.010786938481032848, 0.044638730585575104, 0.0031691468320786953, 0.0006535524735227227, 0.0009872174123302102], "target_probs": 0.9850566983222961}}


{"result": {"time": "2021-02-11 09:52:38.071814", "n_pass": [123, 29, 15], "n_token": 16, "loss": [0.08591105788946152, 0.003913660068064928], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "len", "(", "ref", ")", "source_refs", "ref", "source_refs", "ValidateSourceReference", "(", "ref", "."]}}
{"position": {"error_location": 7, "repair_targets": [1, 9, 11], "repair_candidates": [7, 10, 14, 1, 9, 11]}}
{"prediction": {"error_location": 0.9176757335662842, "repair_targets": [0.9371459484100342, 0.0566704086959362, 0.002277650870382786], "repair_candidates": [0.9371459484100342, 0.0015744903357699513, 0.0566704086959362, 0.002173955086618662, 0.002277650870382786, 0.00015748108853586018], "target_probs": 0.9960939884185791}}


{"result": {"time": "2021-02-11 09:52:38.127627", "n_pass": [124, 30, 16], "n_token": 15, "loss": [0.09037763625383377, 0.006860849913209677], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "len", "(", "ref", ")", "source_refs", "ref", "source_refs", "(", "ref", "."]}}
{"position": {"error_location": 7, "repair_targets": [1, 9, 11], "repair_candidates": [7, 10, 13, 1, 9, 11]}}
{"prediction": {"error_location": 0.9135860204696655, "repair_targets": [0.9075322151184082, 0.07466469705104828, 0.010965692810714245], "repair_candidates": [0.9075322151184082, 0.0011602869490161538, 0.07466469705104828, 0.0050476426258683205, 0.010965692810714245, 0.0006294044433161616], "target_probs": 0.9931626319885254}}


{"result": {"time": "2021-02-11 09:52:38.183363", "n_pass": [125, 31, 17], "n_token": 14, "loss": [0.31771495938301086, 0.009953518398106098], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "len", "(", "ref", ")", "source_refs", "ref", "source_refs", "ref", "."]}}
{"position": {"error_location": 7, "repair_targets": [1, 9, 11], "repair_candidates": [7, 10, 12, 1, 9, 11]}}
{"prediction": {"error_location": 0.7278102040290833, "repair_targets": [0.8668249845504761, 0.11667197197675705, 0.006598910316824913], "repair_candidates": [0.8668249845504761, 0.0022190725430846214, 0.11667197197675705, 0.007110631559044123, 0.006598910316824913, 0.0005743506480939686], "target_probs": 0.990095853805542}}


{"result": {"time": "2021-02-11 09:52:38.238077", "n_pass": [127, 32, 18], "n_token": 13, "loss": [0.12768103182315826, 0.0009801421547308564], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["def ValidateCombinedSourceReferencesString(", "source_refs", ")", ":", "#NEWLINE#", "len", "(", "ref", ")", "source_refs", "ref", "source_refs", "ref"]}}
{"position": {"error_location": 7, "repair_targets": [1, 9, 11], "repair_candidates": [7, 10, 12, 1, 9, 11]}}
{"prediction": {"error_location": 0.8801341652870178, "repair_targets": [0.9897909760475159, 0.008790986612439156, 0.00043837836710736156], "repair_candidates": [0.9897909760475159, 0.0005273098358884454, 0.008790986612439156, 0.00027744073304347694, 0.00043837836710736156, 0.0001748894137563184], "target_probs": 0.9990203380584717}}


{"result": {"time": "2021-02-11 09:52:38.346635", "n_pass": [130, 34, 19], "n_token": 12, "loss": [0.40152135491371155, 0.009483159519731998], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["def ValidateCombinedSourceReferencesString(", "source_refs", ":", "#NEWLINE#", "len", "(", "ref", ")", "source_refs", "ref", "source_refs", "ref"]}}
{"position": {"error_location": 6, "repair_targets": [1, 8, 10], "repair_candidates": [6, 9, 11, 1, 8, 10]}}
{"prediction": {"error_location": 0.6693010330200195, "repair_targets": [0.9595012068748474, 0.02878846600651741, 0.002271984936669469], "repair_candidates": [0.9595012068748474, 0.0073910360224545, 0.02878846600651741, 0.0013390369713306427, 0.002271984936669469, 0.0007083139498718083], "target_probs": 0.9905616641044617}}


{"result": {"time": "2021-02-11 09:52:38.456187", "n_pass": [132, 36, 20], "n_token": 11, "loss": [1.426591157913208, 0.007854350842535496], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["def ValidateCombinedSourceReferencesString(", "source_refs", ":", "len", "(", "ref", ")", "source_refs", "ref", "source_refs", "ref"]}}
{"position": {"error_location": 5, "repair_targets": [1, 7, 9], "repair_candidates": [5, 8, 10, 1, 7, 9]}}
{"prediction": {"error_location": 0.2401261180639267, "repair_targets": [0.9689604043960571, 0.02117246575653553, 0.002043570391833782], "repair_candidates": [0.9689604043960571, 0.006547440774738789, 0.02117246575653553, 0.0006168853142298758, 0.002043570391833782, 0.0006592464633285999], "target_probs": 0.9921764135360718}}


{"result": {"time": "2021-02-11 09:52:38.561571", "n_pass": [134, 38, 21], "n_token": 10, "loss": [0.7811076045036316, 0.014286459423601627], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["def ValidateCombinedSourceReferencesString(", "source_refs", ":", "len", "ref", ")", "source_refs", "ref", "source_refs", "ref"]}}
{"position": {"error_location": 4, "repair_targets": [1, 6, 8], "repair_candidates": [4, 7, 9, 1, 6, 8]}}
{"prediction": {"error_location": 0.4578985571861267, "repair_targets": [0.9394749999046326, 0.0450797900557518, 0.0012603362556546926], "repair_candidates": [0.9394749999046326, 0.013014968484640121, 0.0450797900557518, 0.0003899805305991322, 0.0012603362556546926, 0.0007799178711138666], "target_probs": 0.9858151078224182}}




Minimal simplified tokens:

['def ValidateCombinedSourceReferencesString(', 'source_refs', ':', 'len', 'ref', ')', 'source_refs', 'ref', 'source_refs', 'ref']
