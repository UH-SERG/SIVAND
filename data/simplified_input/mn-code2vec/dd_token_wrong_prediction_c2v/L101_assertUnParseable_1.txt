
path = /scratch/rabin/data/code2vec/transforms/Methods_Test/java-large/test/ahmetaa__zemberek-nlp/experiment/src/test/java/zemberek/morphology/old_analysis/WordAnalyzerTest_assertUnParseable.java
method_name = assertUnParseable
method_body = private void assertUnParseable(DynamicLexiconGraph graph, String... words) { WordAnalyzer parser = new WordAnalyzer(graph); for (String word : words) { List<WordAnalysis> results = parser.analyze(word); Assert.assertTrue("Unexpected parse for:" + word + " parse:" + results, results.size() == 0); } }
predict, score, loss = analyze, 0.7516005635261536, 18.4100399017334

Trace of simplified code(s):
{"time": "2021-02-24 13:53:16.309603", "score": "0.7516", "loss": "18.41", "code": "private void assertUnParseable(DynamicLexiconGraph graph, String... words) { WordAnalyzer parser = new WordAnalyzer(graph); for (String word : words) { List<WordAnalysis> results = parser.analyze(word); Assert.assertTrue(\"Unexpected parse for:\" + word + \" parse:\" + results, results.size() == 0); } }", "n_tokens": 112, "n_pass": [1, 1, 1]}
{"time": "2021-02-24 13:53:21.986496", "score": "0.8757", "loss": "19.3262", "code": "private void assertUnParseable(DynamicLexiconGraph graph, String... words) { WordAnalyzer parser = new WordAnalyzer(graph); for (String word : words) { List<WordAnalysis> results = parser.analyze(word); Assert.assertTrue(\"Unexpected parse for:\" + word +size() == 0); } }", "n_tokens": 98, "n_pass": [26, 3, 2]}
{"time": "2021-02-24 13:53:24.798557", "score": "0.8697", "loss": "19.1418", "code": "private void assertUnParseable(DynamicLexiconGraph graph, String... words) { WordAnalyzer parser = new WordAnalyzer(graph); for (String word : words) { List<WordAnalysis> results = parser.analyze(word); Assert.assertTrue(size() == 0); } }", "n_tokens": 84, "n_pass": [32, 4, 3]}
{"time": "2021-02-24 13:53:27.639140", "score": "0.8953", "loss": "19.5406", "code": "private void assertUnParseable(DynamicLexiconGraph graph, String... words) { WordAnalyzer parser = new WordAnalyzer(graph); for (String word : words) { List<WordAnalysis> results = parser.analyze(word); Assert.assertTrue(0); } }", "n_tokens": 77, "n_pass": [51, 5, 4]}
{"time": "2021-02-24 13:53:30.472838", "score": "0.9155", "loss": "19.4895", "code": "private void assertUnParseable(DynamicLexiconGraph graph, String... words) {  WordAnalyzer(graph); for (String word : words) { List<WordAnalysis> results = parser.analyze(word); Assert.assertTrue(0); } }", "n_tokens": 70, "n_pass": [55, 6, 5]}
{"time": "2021-02-24 13:53:33.255396", "score": "0.8508", "loss": "20.756", "code": "private void assertUnParseable(DynamicLexiconGraph graph, String... words) { for (String word : words) { List<WordAnalysis> results = parser.analyze(word); Assert.assertTrue(0); } }", "n_tokens": 63, "n_pass": [56, 7, 6]}
{"time": "2021-02-24 13:53:36.107233", "score": "0.9552", "loss": "23.59", "code": "private void assertUnParseable(DynamicLexiconGraph graph, String... words) { for (String word : words) { List<WordAnalysis> results = parser.analyze(word0); } }", "n_tokens": 56, "n_pass": [61, 8, 7]}
{"time": "2021-02-24 13:53:39.357686", "score": "0.9552", "loss": "23.59", "code": "private void assertUnParseable(DynamicLexiconGraph graph, String words) { for (String word : words) { List<WordAnalysis> results = parser.analyze(word0); } }", "n_tokens": 53, "n_pass": [92, 9, 8]}
{"time": "2021-02-24 13:53:42.160723", "score": "0.9843", "loss": "25.2333", "code": "private void assertUnParseable(DynamicLexiconGraph graph, String words) { for (String word : words) { Listresults = parser.analyze(word0); } }", "n_tokens": 49, "n_pass": [99, 10, 9]}
{"time": "2021-02-24 13:53:44.991485", "score": "0.388", "loss": "19.9401", "code": "private void assertUnParseable(DynamicLexiconGraph graph, String words) { for (String word : words) { Listparser.analyze(word0); } }", "n_tokens": 45, "n_pass": [100, 11, 10]}
{"time": "2021-02-24 13:53:51.855566", "score": "0.3893", "loss": "19.8318", "code": "private void assertUnParseable(DynamicLexiconGraph graph, String words) { for (String word : words) { Listparser.analyze(); } }", "n_tokens": 43, "n_pass": [142, 13, 11]}
{"time": "2021-02-24 13:53:54.628585", "score": "0.3893", "loss": "19.8318", "code": " void assertUnParseable(DynamicLexiconGraph graph, String words) { for (String word : words) { Listparser.analyze(); } }", "n_tokens": 42, "n_pass": [145, 14, 12]}
{"time": "2021-02-24 13:53:57.405707", "score": "0.3893", "loss": "19.8318", "code": "void assertUnParseable(DynamicLexiconGraph graph, String words) { for (String word : words) { Listparser.analyze(); } }", "n_tokens": 41, "n_pass": [146, 15, 13]}
{"time": "2021-02-24 13:54:01.145142", "score": "0.9221", "loss": "25.9594", "code": "void assertUnParseable(DynamicLexiconGraph graph, String words) { for (String word : words) {parser.analyze(); } }", "n_tokens": 39, "n_pass": [164, 16, 14]}
{"time": "2021-02-24 13:54:03.923760", "score": "0.9024", "loss": "22.3296", "code": "void assertUnParseable(DynamicLexiconGraph graph, String words) { for (String word : words) {analyze(); } }", "n_tokens": 37, "n_pass": [165, 17, 15]}
{"time": "2021-02-24 13:54:13.204835", "score": "0.9024", "loss": "22.3296", "code": "void assertUnParseable(DynamicLexiconGraph graph, String words) { for (String word : words) {analyze();} }", "n_tokens": 36, "n_pass": [223, 18, 16]}
{"time": "2021-02-24 13:54:15.973826", "score": "0.9024", "loss": "22.3296", "code": "void assertUnParseable(DynamicLexiconGraph graph, String words) { for (String word : words) {analyze();}}", "n_tokens": 35, "n_pass": [224, 19, 17]}
{"time": "2021-02-24 13:54:19.651728", "score": "0.9024", "loss": "22.3296", "code": "void assertUnParseable(DynamicLexiconGraph graph,String words) { for (String word : words) {analyze();}}", "n_tokens": 34, "n_pass": [234, 20, 18]}
{"time": "2021-02-24 13:54:22.424172", "score": "0.9024", "loss": "22.3296", "code": "void assertUnParseable(DynamicLexiconGraph graph,String words){ for (String word : words) {analyze();}}", "n_tokens": 33, "n_pass": [239, 21, 19]}
{"time": "2021-02-24 13:54:25.222402", "score": "0.9024", "loss": "22.3296", "code": "void assertUnParseable(DynamicLexiconGraph graph,String words){for (String word : words) {analyze();}}", "n_tokens": 32, "n_pass": [241, 22, 20]}
{"time": "2021-02-24 13:54:27.990586", "score": "0.9024", "loss": "22.3296", "code": "void assertUnParseable(DynamicLexiconGraph graph,String words){for(String word : words) {analyze();}}", "n_tokens": 31, "n_pass": [243, 23, 21]}
{"time": "2021-02-24 13:54:30.748480", "score": "0.9024", "loss": "22.3296", "code": "void assertUnParseable(DynamicLexiconGraph graph,String words){for(String word: words) {analyze();}}", "n_tokens": 30, "n_pass": [248, 24, 22]}
{"time": "2021-02-24 13:54:33.510452", "score": "0.9024", "loss": "22.3296", "code": "void assertUnParseable(DynamicLexiconGraph graph,String words){for(String word:words) {analyze();}}", "n_tokens": 29, "n_pass": [250, 25, 23]}
{"time": "2021-02-24 13:54:36.283941", "score": "0.9024", "loss": "22.3296", "code": "void assertUnParseable(DynamicLexiconGraph graph,String words){for(String word:words){analyze();}}", "n_tokens": 28, "n_pass": [253, 26, 24]}

Minimal simplified code:
void assertUnParseable(DynamicLexiconGraph graph,String words){for(String word:words){analyze();}}

