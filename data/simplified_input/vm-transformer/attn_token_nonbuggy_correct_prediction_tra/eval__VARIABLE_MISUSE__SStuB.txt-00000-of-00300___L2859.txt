
Original sample:

{"has_bug": false, "bug_kind": 0, "bug_kind_name": "NONE", "source_tokens": ["#NEWLINE#", "def tag(", "self", ",", "text", ",", "tokenize", "=", "True", ")", ":", "#NEWLINE#", "#INDENT#", "'Tag a string `text`.'", "#NEWLINE#", "return", "pattern_tag", "(", "text", ",", "tokenize", ")"], "error_location": [0], "repair_targets": [], "repair_candidates": [6, 20, 4, 18, 2], "provenances": [{"datasetProvenance": {"datasetName": "ETHPy150Open", "filepath": "sloria/TextBlob/textblob/en/taggers.py", "license": "mit", "note": "license: bigquery_api"}}], "txt_file": "eval__VARIABLE_MISUSE__SStuB.txt-00000-of-00300", "js_count": 2859, "results": {"model": "transformer", "prob": {"loc": [[0.9982092380523682, 9.271217095374595e-06, 2.9398273682090803e-07, 2.187732839331602e-08, 5.204827289162495e-07, 8.332444956238305e-09, 8.264320058515295e-06, 2.2661095044895774e-07, 3.334978160296487e-08, 2.491572503870998e-09, 1.4526042591000987e-08, 6.280420450366364e-08, 2.9151904001878393e-08, 1.0626857260831457e-07, 5.899098809436509e-08, 8.1303470622629e-09, 1.9873982459728268e-09, 7.215317054942716e-08, 0.00015465622709598392, 7.461670037400836e-08, 0.0016165607376024127, 3.140821434044483e-07]], "pointer": [[0.0, 0.0, 0.07096011191606522, 0.0, 0.07815787941217422, 0.0, 0.8397749066352844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010410916991531849, 0.0, 0.0006961695617064834, 0.0]], "target": [0.0]}, "loss": [0.0017921352991834283, 0.0], "acc": [1.0, 0.0, 0.0, 0.0]}}


All source tokens:

['#NEWLINE#', 'def tag(', 'self', ',', 'text', ',', 'tokenize', '=', 'True', ')', ':', '#NEWLINE#', '#INDENT#', "'Tag a string `text`.'", '#NEWLINE#', 'return', 'pattern_tag', '(', 'text', ',', 'tokenize', ')']


All attention probs:

[0.04684862121939659, 0.025271138176321983, 0.10179658234119415, 0.03713880106806755, 0.06278907507658005, 0.038752079010009766, 0.10019586235284805, 0.035238467156887054, 0.03871489688754082, 0.03243493288755417, 0.03851865231990814, 0.03496469929814339, 0.026304999366402626, 0.028709791600704193, 0.025779372081160545, 0.04190002754330635, 0.03241628408432007, 0.022348735481500626, 0.07010883837938309, 0.02571818046271801, 0.08862433582544327, 0.045425623655319214]


Top-k source tokens:

['self', 'tokenize', 'tokenize', 'text', 'text', '#NEWLINE#', ')', 'return', ',', 'True']


Top-k attention probs:

[0.10179658234119415, 0.10019586235284805, 0.08862433582544327, 0.07010883837938309, 0.06278907507658005, 0.04684862121939659, 0.045425623655319214, 0.04190002754330635, 0.038752079010009766, 0.03871489688754082]
