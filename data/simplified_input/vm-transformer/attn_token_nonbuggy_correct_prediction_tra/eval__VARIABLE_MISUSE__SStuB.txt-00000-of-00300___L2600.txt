
Original sample:

{"has_bug": false, "bug_kind": 0, "bug_kind_name": "NONE", "source_tokens": ["#NEWLINE#", "def label_from_latent(", "self", ",", "h", ")", ":", "#NEWLINE#", "#INDENT#", "return", "h", "[", "(", "h", "<", "self", ".", "n_labels", ")", "]"], "error_location": [0], "repair_targets": [], "repair_candidates": [4, 10, 13, 2, 15], "provenances": [{"datasetProvenance": {"datasetName": "ETHPy150Open", "filepath": "pystruct/pystruct/pystruct/models/latent_node_crf.py", "license": "bsd-2-clause", "note": "license: bigquery_api"}}], "txt_file": "eval__VARIABLE_MISUSE__SStuB.txt-00000-of-00300", "js_count": 2600, "results": {"model": "transformer", "prob": {"loc": [[0.8266122341156006, 1.4233618458092678e-05, 3.594549866647867e-07, 1.0933616323427486e-07, 1.444013378204545e-06, 8.8750930160586e-08, 3.2327156418432423e-07, 3.4449379882062203e-07, 2.2708127289661206e-07, 9.078625851088873e-09, 0.14532528817653656, 1.1289140289250099e-08, 4.008627740859083e-08, 0.027487948536872864, 1.545468819585949e-07, 0.0005555073148570955, 1.2463686971386778e-06, 3.879225118907925e-07, 6.076276548583337e-08, 4.300006395396849e-08]], "pointer": [[0.0, 0.0, 0.9020411372184753, 0.0, 0.015092873014509678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00046126259258016944, 0.0, 0.0, 0.00037960452027618885, 0.0, 0.08202523738145828, 0.0, 0.0, 0.0, 0.0]], "target": [0.0]}, "loss": [0.19041968882083893, 0.0], "acc": [1.0, 0.0, 0.0, 0.0]}}


All source tokens:

['#NEWLINE#', 'def label_from_latent(', 'self', ',', 'h', ')', ':', '#NEWLINE#', '#INDENT#', 'return', 'h', '[', '(', 'h', '<', 'self', '.', 'n_labels', ')', ']']


All attention probs:

[0.05248808115720749, 0.028408987447619438, 0.1179838478565216, 0.04196108877658844, 0.08323439210653305, 0.03875630721449852, 0.03399752452969551, 0.03695094957947731, 0.034343574196100235, 0.051563385874032974, 0.09576539695262909, 0.034832462668418884, 0.03728262707591057, 0.08834449201822281, 0.028806664049625397, 0.08510638773441315, 0.019530896097421646, 0.020351866260170937, 0.02495936118066311, 0.04533170163631439]


Top-k source tokens:

['self', 'h', 'h', 'self', 'h', '#NEWLINE#', 'return', ']', ',', ')']


Top-k attention probs:

[0.1179838478565216, 0.09576539695262909, 0.08834449201822281, 0.08510638773441315, 0.08323439210653305, 0.05248808115720749, 0.051563385874032974, 0.04533170163631439, 0.04196108877658844, 0.03875630721449852]
