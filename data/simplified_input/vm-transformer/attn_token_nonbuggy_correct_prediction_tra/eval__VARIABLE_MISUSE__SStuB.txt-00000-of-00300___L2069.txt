
Original sample:

{"has_bug": false, "bug_kind": 0, "bug_kind_name": "NONE", "source_tokens": ["#NEWLINE#", "def _test_pipeline_timer_manager(", "cl", ",", "proto", ")", ":", "#NEWLINE#", "#INDENT#", "with", "cl", ".", "pipeline", "(", ")", "as", "pipe", ":", "#NEWLINE#", "#INDENT#", "with", "pipe", ".", "timer", "(", "'foo'", ")", ":", "#NEWLINE#", "#INDENT#", "pass", "#NEWLINE#", "#UNINDENT#", "#UNINDENT#", "_timer_check", "(", "cl", ".", "_sock", ",", "1", ",", "proto", ",", "'foo'", ",", "'ms'", ")"], "error_location": [0], "repair_targets": [], "repair_candidates": [2, 10, 36, 4, 42, 16, 21], "provenances": [{"datasetProvenance": {"datasetName": "ETHPy150Open", "filepath": "jsocol/pystatsd/statsd/tests.py", "license": "mit", "note": "license: bigquery_api"}}], "txt_file": "eval__VARIABLE_MISUSE__SStuB.txt-00000-of-00300", "js_count": 2069, "results": {"model": "transformer", "prob": {"loc": [[0.9332098960876465, 7.549860129074659e-06, 7.276707947312389e-07, 1.0823021767691898e-07, 6.538222805829719e-06, 9.264689282417748e-08, 1.9417261398757546e-07, 2.751833676484239e-07, 2.5868146735774644e-07, 9.15999720518812e-09, 5.837513526785187e-06, 4.797612405127438e-07, 1.755897329758227e-07, 3.4198378671135288e-06, 2.0289742678869516e-05, 4.417306911363994e-07, 7.438837656081887e-06, 3.863528661440796e-07, 4.6741740789002506e-07, 1.8044298144559434e-07, 8.41426750497476e-09, 4.596017788571771e-06, 4.3954929651590646e-07, 1.8752357391349506e-06, 2.948180053863325e-06, 8.21166941022966e-06, 1.1439529998824582e-06, 3.3826397611846915e-06, 7.478062116206274e-07, 3.0555739272131177e-07, 2.6566547148831887e-06, 6.395752620846906e-07, 6.568211006197089e-07, 4.798536679118115e-07, 2.422005991320475e-07, 7.683686220616437e-08, 0.0638846680521965, 1.097764015867142e-05, 5.885281098017003e-07, 1.3744307807428413e-06, 2.322724412806565e-06, 1.3547066828323295e-06, 0.0027865227311849594, 1.849207819759613e-06, 2.9477189400495263e-06, 1.9406793398957234e-06, 7.644963261554949e-06, 4.737905783258611e-06]], "pointer": [[0.0, 0.0, 0.046868953853845596, 0.0, 0.045673880726099014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02468176744878292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8492949604988098, 0.0, 0.0, 0.0, 0.0, 0.0292899701744318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0006972846458666027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0034931995905935764, 0.0, 0.0, 0.0, 0.0, 0.0]], "target": [0.0]}, "loss": [0.06912534683942795, 0.0], "acc": [1.0, 0.0, 0.0, 0.0]}}


All source tokens:

['#NEWLINE#', 'def _test_pipeline_timer_manager(', 'cl', ',', 'proto', ')', ':', '#NEWLINE#', '#INDENT#', 'with', 'cl', '.', 'pipeline', '(', ')', 'as', 'pipe', ':', '#NEWLINE#', '#INDENT#', 'with', 'pipe', '.', 'timer', '(', "'foo'", ')', ':', '#NEWLINE#', '#INDENT#', 'pass', '#NEWLINE#', '#UNINDENT#', '#UNINDENT#', '_timer_check', '(', 'cl', '.', '_sock', ',', '1', ',', 'proto', ',', "'foo'", ',', "'ms'", ')']


All attention probs:

[0.03146970272064209, 0.019374776631593704, 0.057176630944013596, 0.02519521489739418, 0.06997460126876831, 0.02403351664543152, 0.017429169267416, 0.01895848475396633, 0.01794416829943657, 0.018713010475039482, 0.04066505655646324, 0.014247558079659939, 0.014468931593000889, 0.01641096919775009, 0.014126092195510864, 0.017178481444716454, 0.048137493431568146, 0.012707235291600227, 0.014422480948269367, 0.014671670272946358, 0.013289835304021835, 0.030720196664333344, 0.009090597741305828, 0.009740387089550495, 0.012896469794213772, 0.015261820517480373, 0.008459488861262798, 0.011556776240468025, 0.011359133757650852, 0.011212070472538471, 0.019874393939971924, 0.014512088149785995, 0.016974441707134247, 0.018979046493768692, 0.02823754772543907, 0.014227439649403095, 0.04702205955982208, 0.009922041557729244, 0.010678675957024097, 0.013557499274611473, 0.018739117309451103, 0.01286196056753397, 0.06863754242658615, 0.013437719084322453, 0.01247487310320139, 0.012710192240774632, 0.013656086288392544, 0.012605234049260616]


Top-k source tokens:

['proto', 'proto', 'cl', 'pipe', 'cl', 'cl', '#NEWLINE#', 'pipe', '_timer_check', ',']


Top-k attention probs:

[0.06997460126876831, 0.06863754242658615, 0.057176630944013596, 0.048137493431568146, 0.04702205955982208, 0.04066505655646324, 0.03146970272064209, 0.030720196664333344, 0.02823754772543907, 0.02519521489739418]
