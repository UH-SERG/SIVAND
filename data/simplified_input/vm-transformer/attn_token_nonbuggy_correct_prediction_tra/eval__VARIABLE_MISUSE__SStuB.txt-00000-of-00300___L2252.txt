
Original sample:

{"has_bug": false, "bug_kind": 0, "bug_kind_name": "NONE", "source_tokens": ["#NEWLINE#", "def __lt__(", "self", ",", "other", ")", ":", "#NEWLINE#", "#INDENT#", "return", "(", "self", ".", "tag", "<", "other", ".", "tag", ")"], "error_location": [0], "repair_targets": [], "repair_candidates": [2, 11, 4, 15], "provenances": [{"datasetProvenance": {"datasetName": "ETHPy150Open", "filepath": "caesar0301/treelib/treelib/node.py", "license": "apache-2.0", "note": "license: manual_eval"}}], "txt_file": "eval__VARIABLE_MISUSE__SStuB.txt-00000-of-00300", "js_count": 2252, "results": {"model": "transformer", "prob": {"loc": [[0.9994244575500488, 2.173904022129136e-06, 1.2495210057750228e-06, 1.4701501349634327e-08, 1.6432398552979066e-08, 2.2961547330169196e-08, 1.005898226935642e-07, 1.3198898329846998e-07, 1.2362521317754727e-07, 7.909082277990365e-09, 4.664852326641267e-08, 0.000495372514706105, 1.1022589205822442e-06, 1.606583133195727e-08, 9.668537614970774e-08, 7.281535363290459e-05, 1.954176013896358e-06, 1.1948185374421882e-07, 1.4407258674964396e-07]], "pointer": [[0.0, 0.0, 0.3664764165878296, 0.0, 0.5506976842880249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03223959356546402, 0.0, 0.0, 0.0, 0.050586290657520294, 0.0, 0.0, 0.0]], "target": [0.0]}, "loss": [0.0005757343024015427, 0.0], "acc": [1.0, 0.0, 0.0, 0.0]}}


All source tokens:

['#NEWLINE#', 'def __lt__(', 'self', ',', 'other', ')', ':', '#NEWLINE#', '#INDENT#', 'return', '(', 'self', '.', 'tag', '<', 'other', '.', 'tag', ')']


All attention probs:

[0.06682118773460388, 0.03237877041101456, 0.11038222163915634, 0.048537228256464005, 0.10860283672809601, 0.04339871555566788, 0.035579096525907516, 0.038775261491537094, 0.03631153330206871, 0.05953880399465561, 0.036868270486593246, 0.11121463775634766, 0.026144910603761673, 0.03151106461882591, 0.03199485316872597, 0.08895664662122726, 0.02496280148625374, 0.031139260157942772, 0.03688191622495651]


Top-k source tokens:

['self', 'self', 'other', 'other', '#NEWLINE#', 'return', ',', ')', '#NEWLINE#', ')']


Top-k attention probs:

[0.11121463775634766, 0.11038222163915634, 0.10860283672809601, 0.08895664662122726, 0.06682118773460388, 0.05953880399465561, 0.048537228256464005, 0.04339871555566788, 0.038775261491537094, 0.03688191622495651]
