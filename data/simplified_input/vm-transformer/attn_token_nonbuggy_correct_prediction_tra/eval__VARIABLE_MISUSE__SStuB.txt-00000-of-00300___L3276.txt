
Original sample:

{"has_bug": false, "bug_kind": 0, "bug_kind_name": "NONE", "source_tokens": ["#NEWLINE#", "def pack_word(", "self", ",", "offset", ",", "word", ")", ":", "#NEWLINE#", "#INDENT#", "'\\n        Applies the little-endian WORD (2 bytes) to the relative offset.\\n        Arguments:\\n        - `offset`: The relative offset from the start of the block.\\n        - `word`: The data to apply.\\n        '", "#NEWLINE#", "o", "=", "(", "self", ".", "_offset", "+", "offset", ")", "#NEWLINE#", "return", "struct", ".", "pack_into", "(", "'<H'", ",", "self", ".", "_buf", ",", "o", ",", "word", ")"], "error_location": [0], "repair_targets": [], "repair_candidates": [2, 16, 30, 6, 36, 4, 20, 13, 34], "provenances": [{"datasetProvenance": {"datasetName": "ETHPy150Open", "filepath": "williballenthin/shellbags/BinaryParser.py", "license": "apache-2.0", "note": "license: bigquery_api"}}], "txt_file": "eval__VARIABLE_MISUSE__SStuB.txt-00000-of-00300", "js_count": 3276, "results": {"model": "transformer", "prob": {"loc": [[0.9950803518295288, 8.480707947455812e-06, 4.1269890971307177e-07, 6.989538547941265e-08, 1.2097478929717909e-06, 6.23595752813344e-08, 9.315390343545005e-06, 4.017146792989479e-08, 1.022089932689596e-07, 2.779679846298677e-07, 1.5443360723566002e-07, 5.107769993628608e-07, 1.9449798571713472e-07, 3.5099217257084092e-06, 4.938942055332518e-08, 1.4098210954216484e-07, 0.0003000555152539164, 3.115042659374012e-07, 1.6081687093105757e-08, 1.3468601878230402e-07, 0.0028280450496822596, 1.06367997432244e-06, 2.2158754120482627e-07, 2.1914457803973164e-08, 2.989233038874772e-08, 1.085627374664e-07, 6.60793464390963e-09, 1.610886357639174e-07, 1.0475613635207992e-05, 5.925263621975319e-07, 0.0004890640848316252, 4.023460178359528e-07, 1.1796533527785869e-08, 3.8417098835452634e-07, 0.00033054681262001395, 3.205360030733573e-07, 0.0009312744368799031, 1.892363115985063e-06]], "pointer": [[0.0, 0.0, 0.004074806347489357, 0.0, 0.6790987849235535, 0.0, 0.23209704458713531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03413679450750351, 0.0, 0.0, 9.026658517541364e-05, 0.0, 0.0, 0.0, 0.04844434931874275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.781005842844024e-05, 0.0, 0.0, 0.0, 0.00028494204161688685, 0.0, 0.0016951137222349644, 0.0]], "target": [0.0]}, "loss": [0.004931785631924868, 0.0], "acc": [1.0, 0.0, 0.0, 0.0]}}


All source tokens:

['#NEWLINE#', 'def pack_word(', 'self', ',', 'offset', ',', 'word', ')', ':', '#NEWLINE#', '#INDENT#', "'\\n        Applies the little-endian WORD (2 bytes) to the relative offset.\\n        Arguments:\\n        - `offset`: The relative offset from the start of the block.\\n        - `word`: The data to apply.\\n        '", '#NEWLINE#', 'o', '=', '(', 'self', '.', '_offset', '+', 'offset', ')', '#NEWLINE#', 'return', 'struct', '.', 'pack_into', '(', "'<H'", ',', 'self', '.', '_buf', ',', 'o', ',', 'word', ')']


All attention probs:

[0.031224850565195084, 0.018805088475346565, 0.0802973136305809, 0.027284296229481697, 0.04937205836176872, 0.023087240755558014, 0.059500329196453094, 0.021654251962900162, 0.017773335799574852, 0.02170882374048233, 0.02191660925745964, 0.023513151332736015, 0.020157290622591972, 0.04913412034511566, 0.013921106234192848, 0.011593514122068882, 0.044318560510873795, 0.009402423165738583, 0.01481157261878252, 0.010063202120363712, 0.06038377434015274, 0.009766492992639542, 0.017880387604236603, 0.022788366302847862, 0.021439282223582268, 0.008533960208296776, 0.013430321589112282, 0.013159127905964851, 0.011661010794341564, 0.012930475175380707, 0.03754144906997681, 0.01217161025851965, 0.01786716841161251, 0.02399265393614769, 0.047140516340732574, 0.02735368348658085, 0.04826853424310684, 0.024152059108018875]


Top-k source tokens:

['self', 'offset', 'word', 'offset', 'o', 'word', 'o', 'self', 'self', '#NEWLINE#']


Top-k attention probs:

[0.0802973136305809, 0.06038377434015274, 0.059500329196453094, 0.04937205836176872, 0.04913412034511566, 0.04826853424310684, 0.047140516340732574, 0.044318560510873795, 0.03754144906997681, 0.031224850565195084]
