
Original sample:

{"has_bug": false, "bug_kind": 0, "bug_kind_name": "NONE", "source_tokens": ["#NEWLINE#", "def __init__(", "self", ",", "callback_function", "=", "None", ")", ":", "#NEWLINE#", "#INDENT#", "self", ".", "callback_function", "=", "callback_function"], "error_location": [0], "repair_targets": [], "repair_candidates": [4, 13, 15, 2, 11], "provenances": [{"datasetProvenance": {"datasetName": "ETHPy150Open", "filepath": "fp7-ofelia/ocf/expedient/doc/plugins/samples/aggregate/sr_manager/src/communications/XmlRpcAPI.py", "license": "bsd-3-clause", "note": "license: manual_eval"}}], "txt_file": "eval__VARIABLE_MISUSE__SStuB.txt-00000-of-00300", "js_count": 2407, "results": {"model": "transformer", "prob": {"loc": [[0.9999693632125854, 5.6048725127766374e-06, 5.916394911764655e-07, 1.4981787899159826e-07, 3.8928902768020635e-07, 7.470034120160562e-07, 2.039766542338839e-07, 1.2848683184074616e-07, 1.717400408551839e-07, 1.9275828435638687e-06, 3.815167701759492e-07, 1.8772162775348988e-06, 6.85047155002394e-07, 2.631999791447015e-07, 2.4729831693548476e-07, 1.7374921299051493e-05]], "pointer": [[0.0, 0.0, 0.3183221220970154, 0.0, 0.6017199754714966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035829655826091766, 0.0, 0.010434355586767197, 0.0, 0.03369388356804848]], "target": [0.0]}, "loss": [3.075552376685664e-05, 0.0], "acc": [1.0, 0.0, 0.0, 0.0]}}


All source tokens:

['#NEWLINE#', 'def __init__(', 'self', ',', 'callback_function', '=', 'None', ')', ':', '#NEWLINE#', '#INDENT#', 'self', '.', 'callback_function', '=', 'callback_function']


All attention probs:

[0.07013358920812607, 0.039747122675180435, 0.08586559444665909, 0.060981202870607376, 0.11653256416320801, 0.05379757657647133, 0.05606621131300926, 0.05065292492508888, 0.04185769334435463, 0.04168558120727539, 0.04508179426193237, 0.09974724054336548, 0.026778899133205414, 0.0530676543712616, 0.04390772804617882, 0.11409663408994675]


Top-k source tokens:

['callback_function', 'callback_function', 'self', 'self', '#NEWLINE#', ',', 'None', '=', 'callback_function', ')']


Top-k attention probs:

[0.11653256416320801, 0.11409663408994675, 0.09974724054336548, 0.08586559444665909, 0.07013358920812607, 0.060981202870607376, 0.05606621131300926, 0.05379757657647133, 0.0530676543712616, 0.05065292492508888]
