
Original sample:

{"has_bug": false, "bug_kind": 0, "bug_kind_name": "NONE", "source_tokens": ["#NEWLINE#", "def _sequential_learning(", "self", ",", "X", ",", "Y", ",", "w", ")", ":", "#NEWLINE#", "#INDENT#", "n_samples", "=", "len", "(", "X", ")", "#NEWLINE#", "(", "objective", ",", "positive_slacks", ")", "=", "(", "0", ",", "0", ")", "#NEWLINE#", "if", "(", "self", ".", "batch_size", "in", "[", "None", ",", "1", "]", ")", ":", "#NEWLINE#", "#INDENT#", "for", "(", "x", ",", "y", ")", "in", "zip", "(", "X", ",", "Y", ")", ":", "#NEWLINE#", "#INDENT#", "(", "y_hat", ",", "delta_joint_feature", ",", "slack", ",", "loss", ")", "=", "find_constraint", "(", "self", ".", "model", ",", "x", ",", "y", ",", "w", ")", "#NEWLINE#", "objective", "+=", "slack", "#NEWLINE#", "if", "(", "slack", ">", "0", ")", ":", "#NEWLINE#", "#INDENT#", "positive_slacks", "+=", "1", "#NEWLINE#", "#UNINDENT#", "self", ".", "_solve_subgradient", "(", "delta_joint_feature", ",", "n_samples", ",", "w", ")", "#NEWLINE#", "#UNINDENT#", "#UNINDENT#", "else", ":", "#NEWLINE#", "#INDENT#", "if", "(", "self", ".", "batch_size", "==", "(", "-", "1", ")", ")", ":", "#NEWLINE#", "#INDENT#", "slices", "=", "[", "slice", "(", "0", ",", "len", "(", "X", ")", ")", "]", "#NEWLINE#", "#UNINDENT#", "else", ":", "#NEWLINE#", "#INDENT#", "n_batches", "=", "int", "(", "np", ".", "ceil", "(", "(", "float", "(", "len", "(", "X", ")", ")", "/", "self", ".", "batch_size", ")", ")", ")", "#NEWLINE#", "slices", "=", "gen_even_slices", "(", "n_samples", ",", "n_batches", ")", "#NEWLINE#", "#UNINDENT#", "for", "batch", "in", "slices", ":", "#NEWLINE#", "#INDENT#", "X_b", "=", "X", "[", "batch", "]", "#NEWLINE#", "Y_b", "=", "Y", "[", "batch", "]", "#NEWLINE#", "Y_hat", "=", "self", ".", "model", ".", "batch_loss_augmented_inference", "(", "X_b", ",", "Y_b", ",", "w", ",", "relaxed", "=", "True", ")", "#NEWLINE#", "delta_joint_feature", "=", "(", "self", ".", "model", ".", "batch_joint_feature", "(", "X_b", ",", "Y_b", ")", "-", "self", ".", "model", ".", "batch_joint_feature", "(", "X_b", ",", "Y_hat", ")", ")", "#NEWLINE#", "loss", "=", "np", ".", "sum", "(", "self", ".", "model", ".", "batch_loss", "(", "Y_b", ",", "Y_hat", ")", ")", "#NEWLINE#", "violation", "=", "np", ".", "maximum", "(", "0", ",", "(", "loss", "-", "np", ".", "dot", "(", "w", ",", "delta_joint_feature", ")", ")", ")", "#NEWLINE#", "objective", "+=", "violation", "#NEWLINE#", "positive_slacks", "+=", "self", ".", "batch_size", "#NEWLINE#", "self", ".", "_solve_subgradient", "(", "(", "delta_joint_feature", "/", "len", "(", "X_b", ")", ")", ",", "n_samples", ",", "w", ")", "#NEWLINE#", "#UNINDENT#", "#UNINDENT#", "return", "(", "objective", ",", "positive_slacks", ",", "w", ")"], "error_location": [0], "repair_targets": [], "repair_candidates": [51, 81, 8, 83, 112, 221, 287, 319, 330, 189, 199, 206, 195, 217, 237, 248, 313, 6, 58, 204, 202, 219, 239, 266, 64, 154, 184, 70, 254, 281, 13, 110, 182, 317, 4, 17, 56, 144, 167, 197, 135, 178, 191, 209, 250, 268, 272, 296, 49, 79, 23, 99, 298, 328, 21, 86, 294, 326, 68, 88, 92, 66, 108, 228, 289, 309, 2, 34, 75, 104, 123, 171, 211, 231, 242, 260, 300, 304], "provenances": [{"datasetProvenance": {"datasetName": "ETHPy150Open", "filepath": "pystruct/pystruct/pystruct/learners/subgradient_ssvm.py", "license": "bsd-2-clause", "note": "license: bigquery_api"}}], "txt_file": "eval__VARIABLE_MISUSE__SStuB.txt-00000-of-00300", "js_count": 1271, "results": {"model": "transformer", "prob": {"loc": [[0.45719048380851746, 1.7163330312541802e-06, 3.805130575074145e-07, 5.272112346688118e-08, 1.8209771042165812e-06, 5.146095816144225e-08, 2.6244085802318295e-06, 5.1198231432181274e-08, 2.7235321340413066e-06, 4.052563085110705e-08, 5.905639710590549e-08, 7.498786658288736e-08, 5.6091646882805435e-08, 4.692397396865999e-06, 5.242986134135208e-08, 1.8736384888029534e-08, 1.9839163201140764e-07, 0.0020065682474523783, 2.196833008838439e-07, 8.387461747361158e-08, 2.0985837068110413e-08, 9.766524271981325e-06, 6.965409227177588e-08, 8.265561336884275e-05, 2.364307860602821e-08, 1.435499683566377e-07, 4.633430137346295e-07, 2.5053926947293803e-05, 2.424930869437958e-07, 2.2200487364898436e-05, 3.974158460096078e-07, 1.3667622056345863e-07, 1.259019484223245e-07, 9.617950524898333e-08, 3.224854663130827e-05, 7.326391227024942e-08, 5.846612225468562e-07, 7.667832164770516e-07, 8.895507562556304e-06, 1.3267285794427153e-06, 4.313521628773742e-07, 1.4125672578302328e-06, 2.224728206101645e-07, 1.2049606823438808e-07, 2.536618239901145e-07, 1.64365957289192e-07, 1.4753649679732916e-07, 1.5666614672227297e-07, 4.7372935796374804e-08, 1.4164741060085362e-06, 1.0022070995319154e-07, 1.553146466903854e-05, 3.034286066849745e-08, 4.6892164817791127e-08, 6.093509341553727e-07, 4.6317424562403176e-07, 0.0013945888495072722, 1.247394294523474e-07, 0.0019598877988755703, 6.859102086309576e-08, 2.7167573080078e-07, 1.318525164606399e-07, 9.0236468963667e-08, 3.115034630241098e-08, 1.818518830987159e-05, 1.8702583304275322e-07, 7.554632247774862e-06, 1.9298953191082546e-07, 1.3861662409908604e-05, 2.004583592452036e-07, 1.9855497157550417e-05, 4.465470127001936e-08, 1.6169674665889033e-07, 4.363007246865891e-05, 2.894456656576949e-07, 1.0970277799060568e-05, 1.3027725742631446e-07, 1.063104893006539e-08, 1.4080099219881959e-07, 0.0001990570453926921, 6.257437235035468e-07, 0.0019063622457906604, 1.7662151208241994e-07, 0.0010966225527226925, 2.3041982899485447e-07, 2.4218064709202736e-07, 8.860957314027473e-05, 1.0069442168969545e-06, 0.0011838775826618075, 2.555908622525749e-07, 1.6929344326399587e-07, 1.998938330416422e-07, 0.00144762743730098, 1.2354917089396622e-06, 1.3971998669148888e-06, 1.493594936619047e-07, 7.858732260501711e-07, 5.199092356633628e-07, 2.205601390414813e-07, 0.00010255665256408975, 7.403698418784188e-07, 8.856027307047043e-06, 3.0122080829642073e-07, 2.816939854710654e-07, 8.331520717774765e-08, 4.1653727578250255e-08, 9.329899341992132e-08, 8.04124624664837e-07, 0.002423991449177265, 1.3900244084652513e-06, 0.005294098053127527, 6.123241860223061e-07, 0.0013166299322620034, 5.128416091793042e-07, 3.241288482058735e-07, 2.2511331110308674e-07, 2.0785415699720033e-07, 6.590451562260569e-07, 4.112997373795224e-07, 3.900302942838607e-07, 3.2239501024378114e-07, 2.1975034769639024e-07, 3.7397978758235695e-07, 2.4336886781384237e-05, 1.6857426032856893e-07, 7.668219836887147e-07, 1.0102000942424638e-06, 1.2367419913061894e-05, 7.959828280945658e-07, 4.714961050922284e-06, 5.797805329166295e-07, 1.6291788540456764e-07, 8.615865567662695e-07, 2.679404360605986e-07, 1.8787299893574527e-07, 3.051256044273032e-06, 1.110320155817135e-07, 9.17802481126273e-07, 1.861277041825815e-06, 3.544360538398905e-07, 7.67572237236891e-06, 1.7649726657964493e-07, 7.762950815504155e-08, 6.817459166086337e-07, 0.002855676459148526, 2.364291304957078e-07, 2.7816636816169193e-07, 3.5038897294725757e-07, 2.417908717688988e-07, 2.3152074390964117e-07, 9.006473078443378e-07, 4.900714998257172e-07, 3.297339787877718e-07, 2.8085167969038594e-07, 1.8706972696236335e-05, 2.027387040470785e-07, 7.841824611887205e-08, 1.8524590927881945e-07, 5.155396820555325e-07, 1.5063561420447513e-07, 2.2123713279142976e-06, 2.0362075758839637e-07, 1.8414013425172016e-07, 2.2526747045503726e-07, 2.505313716483215e-07, 3.188645791851741e-07, 8.219301435019588e-07, 0.0020331437699496746, 4.954106316290563e-07, 8.416852637083139e-08, 4.6057800773269264e-07, 1.6633866835036315e-05, 1.4495883249310282e-07, 6.628302458011603e-07, 1.6378933764826797e-07, 6.688945859423256e-07, 3.792335121488577e-07, 1.5036148681701889e-07, 5.580933247983921e-06, 6.076972169921646e-08, 6.389283953467384e-06, 6.555173399647174e-07, 0.04779410734772682, 3.6298595773587294e-07, 0.00044535688357427716, 6.466926834036713e-07, 3.0313427146211325e-07, 3.5036055123782717e-07, 1.6497866681675077e-06, 2.6796808015205897e-05, 1.7895638393383706e-07, 0.0002817126514855772, 1.4777187971048988e-06, 4.258074852714344e-07, 1.7625234249862842e-07, 9.554130883770995e-06, 5.179801405574835e-07, 0.015343261882662773, 2.559690983616747e-06, 0.0016948496922850609, 7.935967119010456e-07, 2.2991937953520392e-07, 2.837667580024572e-06, 1.0757251800441736e-07, 0.2859707176685333, 4.183299097348936e-06, 0.002324200700968504, 6.528539984174131e-07, 1.790504597920517e-07, 8.569414603698533e-06, 2.3108223956569418e-07, 6.851639113847341e-07, 5.120253021573262e-08, 2.0099212960644763e-08, 4.4216690753273724e-08, 3.1405321010424814e-08, 5.356119459065667e-07, 0.002119646407663822, 9.920555612552562e-07, 0.007118784822523594, 4.7648262579969014e-07, 0.0033228497486561537, 3.6284302495914744e-07, 1.0032937098003458e-05, 1.1095258969362476e-06, 1.650714511924889e-05, 4.09406027301884e-07, 2.82609931900879e-07, 4.410445853864076e-06, 7.556956234111567e-07, 5.801699671792448e-07, 2.5169862283291877e-07, 6.346905934151437e-08, 2.1042030340368e-08, 5.398675639867179e-08, 8.564250464360157e-08, 6.453778951254208e-07, 0.0018117427825927734, 9.805108902583015e-07, 0.0053592524491250515, 2.9470302820300276e-07, 3.1568390568281757e-07, 1.6431448557341355e-06, 6.135531549489315e-08, 1.0490352586600693e-08, 1.0000923822417462e-07, 6.126428075958756e-08, 1.4651915307695162e-06, 0.002522597787901759, 7.918972073639452e-07, 0.0013277520192787051, 8.005260951904347e-07, 6.14359180417523e-07, 3.803548906944343e-07, 6.592918907699641e-06, 1.9963028989877785e-06, 2.834642316429381e-07, 1.351034768504178e-07, 6.919623274370679e-07, 1.0376733143857564e-06, 2.1798753095936263e-06, 1.262661584178204e-07, 2.775371577001806e-08, 8.396160922075069e-08, 1.0394060012686168e-07, 1.3800597571389517e-06, 0.03917825222015381, 5.348743457034288e-07, 0.0026358780451118946, 8.822387940199405e-07, 7.747866561658157e-07, 1.13276428237441e-06, 7.918390474515036e-05, 7.810726287971193e-07, 3.884485977323493e-07, 1.8673745216801763e-07, 8.101671937765786e-07, 1.3007869483772083e-06, 8.502633863827214e-05, 4.5112980728845287e-07, 4.3711366970455856e-07, 0.001082523725926876, 4.192935136870801e-07, 4.4356426087688305e-07, 1.0167575226205372e-07, 6.501283564830374e-07, 1.7117903325925e-06, 0.018569765612483025, 3.4059982567669067e-07, 0.012187696993350983, 8.312231329909991e-07, 5.315410476214311e-07, 6.210979677234718e-07, 5.351463414626778e-07, 1.5590228940709494e-05, 3.7797482832502283e-07, 0.013911368325352669, 5.400234499575163e-07, 1.3562734238803387e-05, 1.1380494697732502e-06, 0.00016084963863249868, 1.8463249773503776e-07, 3.18495636975058e-07, 4.6529129349437426e-07, 1.703459560076226e-07, 1.0958953566841956e-07, 1.4655793734164035e-07, 7.595980946462078e-07, 2.2963483843341237e-06, 0.00940799806267023, 3.5280316978969495e-07, 1.1986536208041798e-07, 2.3108300410967786e-06, 0.012338646687567234, 2.700352581541665e-07, 1.583336768362642e-07, 1.752406859623079e-07, 0.007737397216260433, 3.414336902096693e-07, 0.004725645761936903, 8.583879775869718e-07, 7.119857059478818e-07, 8.380694112020137e-07, 1.061541752278572e-06, 1.2108067437566206e-07, 7.110139677024563e-07, 0.010168490000069141, 7.528966534664505e-07, 0.0026228101924061775, 4.613632142991264e-07, 0.004506590310484171, 4.5523731273533485e-07]], "pointer": [[0.0, 0.0, 0.0018500419100746512, 0.0, 0.02212079055607319, 0.0, 0.026620494201779366, 0.0, 0.01670890673995018, 0.0, 0.0, 0.0, 0.0, 0.019812913611531258, 0.0, 0.0, 0.0, 0.0009317835792899132, 0.0, 0.0, 0.0, 0.009915581904351711, 0.0, 0.01219324953854084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.513293242780492e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00658434210345149, 0.0, 0.013023077510297298, 0.0, 0.0, 0.0, 0.0, 0.0021100675221532583, 0.0, 0.000858175742905587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028513500466942787, 0.0, 0.013336042873561382, 0.0, 0.010286364704370499, 0.0, 0.01325113233178854, 0.0, 0.0, 0.0, 0.0, 1.129295469581848e-05, 0.0, 0.0, 0.0, 0.0006046364433132112, 0.0, 0.00012327743752393872, 0.0, 0.0042794933542609215, 0.0, 0.0, 0.0006272326572798193, 0.0, 4.58185859315563e-05, 0.0, 0.0, 0.0, 0.0003262103127781302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0032784175127744675, 0.0, 0.0, 0.0, 0.0, 3.831442154478282e-05, 0.0, 0.0, 0.0, 0.005294388625770807, 0.0, 0.006753426510840654, 0.0, 0.011057992465794086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.503033702960238e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007559292949736118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014716730453073978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007892909459769726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02984088473021984, 0.0, 0.0, 0.0, 4.676177559304051e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019397897645831108, 0.0, 0.0, 0.0, 0.010682148858904839, 0.0, 3.977645610575564e-05, 0.0, 0.0, 0.0, 0.0, 0.0114623187109828, 0.0, 5.8661014918470755e-05, 0.0, 0.0, 0.0, 0.0567392073571682, 0.0, 0.21930605173110962, 0.0, 0.0001393887505400926, 0.0, 0.0, 0.027826672419905663, 0.0, 0.006163888145238161, 0.0, 8.198384603019804e-05, 0.0, 0.0, 0.016433779150247574, 0.0, 4.031970092910342e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009363957680761814, 0.0, 0.0023755028378218412, 0.0, 0.009920666925609112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03167534992098808, 0.0, 0.0, 8.531901403330266e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012472162023186684, 0.0, 0.003574975300580263, 0.0, 0.0, 2.3237096684169956e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038800645619630814, 0.0, 0.0007015714654698968, 0.0, 0.0, 0.0, 0.08092772215604782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000212272338103503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007225203327834606, 0.0, 0.0024758961517363787, 0.0, 0.0, 0.0, 0.0238198135048151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00557212857529521, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008471518754959106, 0.0, 0.003840663470327854, 0.0, 0.0, 0.0, 0.0, 0.006102386862039566, 0.0, 0.005934926215559244, 0.0, 0.00858088955283165, 0.0, 0.0002359366771997884, 0.0, 0.0, 0.0, 0.0006922607426531613, 0.0, 0.0, 0.0, 0.0, 0.032899413257837296, 0.0, 0.0, 0.0, 0.02735210955142975, 0.0, 0.0, 0.0, 0.005642490461468697, 0.0, 0.00669151870533824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0010868534445762634, 0.0, 0.001822405494749546, 0.0, 0.0023143889848142862, 0.0]], "target": [0.0]}, "loss": [0.7826550006866455, 0.0], "acc": [1.0, 0.0, 0.0, 0.0]}}


All source tokens:

['#NEWLINE#', 'def _sequential_learning(', 'self', ',', 'X', ',', 'Y', ',', 'w', ')', ':', '#NEWLINE#', '#INDENT#', 'n_samples', '=', 'len', '(', 'X', ')', '#NEWLINE#', '(', 'objective', ',', 'positive_slacks', ')', '=', '(', '0', ',', '0', ')', '#NEWLINE#', 'if', '(', 'self', '.', 'batch_size', 'in', '[', 'None', ',', '1', ']', ')', ':', '#NEWLINE#', '#INDENT#', 'for', '(', 'x', ',', 'y', ')', 'in', 'zip', '(', 'X', ',', 'Y', ')', ':', '#NEWLINE#', '#INDENT#', '(', 'y_hat', ',', 'delta_joint_feature', ',', 'slack', ',', 'loss', ')', '=', 'find_constraint', '(', 'self', '.', 'model', ',', 'x', ',', 'y', ',', 'w', ')', '#NEWLINE#', 'objective', '+=', 'slack', '#NEWLINE#', 'if', '(', 'slack', '>', '0', ')', ':', '#NEWLINE#', '#INDENT#', 'positive_slacks', '+=', '1', '#NEWLINE#', '#UNINDENT#', 'self', '.', '_solve_subgradient', '(', 'delta_joint_feature', ',', 'n_samples', ',', 'w', ')', '#NEWLINE#', '#UNINDENT#', '#UNINDENT#', 'else', ':', '#NEWLINE#', '#INDENT#', 'if', '(', 'self', '.', 'batch_size', '==', '(', '-', '1', ')', ')', ':', '#NEWLINE#', '#INDENT#', 'slices', '=', '[', 'slice', '(', '0', ',', 'len', '(', 'X', ')', ')', ']', '#NEWLINE#', '#UNINDENT#', 'else', ':', '#NEWLINE#', '#INDENT#', 'n_batches', '=', 'int', '(', 'np', '.', 'ceil', '(', '(', 'float', '(', 'len', '(', 'X', ')', ')', '/', 'self', '.', 'batch_size', ')', ')', ')', '#NEWLINE#', 'slices', '=', 'gen_even_slices', '(', 'n_samples', ',', 'n_batches', ')', '#NEWLINE#', '#UNINDENT#', 'for', 'batch', 'in', 'slices', ':', '#NEWLINE#', '#INDENT#', 'X_b', '=', 'X', '[', 'batch', ']', '#NEWLINE#', 'Y_b', '=', 'Y', '[', 'batch', ']', '#NEWLINE#', 'Y_hat', '=', 'self', '.', 'model', '.', 'batch_loss_augmented_inference', '(', 'X_b', ',', 'Y_b', ',', 'w', ',', 'relaxed', '=', 'True', ')', '#NEWLINE#', 'delta_joint_feature', '=', '(', 'self', '.', 'model', '.', 'batch_joint_feature', '(', 'X_b', ',', 'Y_b', ')', '-', 'self', '.', 'model', '.', 'batch_joint_feature', '(', 'X_b', ',', 'Y_hat', ')', ')', '#NEWLINE#', 'loss', '=', 'np', '.', 'sum', '(', 'self', '.', 'model', '.', 'batch_loss', '(', 'Y_b', ',', 'Y_hat', ')', ')', '#NEWLINE#', 'violation', '=', 'np', '.', 'maximum', '(', '0', ',', '(', 'loss', '-', 'np', '.', 'dot', '(', 'w', ',', 'delta_joint_feature', ')', ')', ')', '#NEWLINE#', 'objective', '+=', 'violation', '#NEWLINE#', 'positive_slacks', '+=', 'self', '.', 'batch_size', '#NEWLINE#', 'self', '.', '_solve_subgradient', '(', '(', 'delta_joint_feature', '/', 'len', '(', 'X_b', ')', ')', ',', 'n_samples', ',', 'w', ')', '#NEWLINE#', '#UNINDENT#', '#UNINDENT#', 'return', '(', 'objective', ',', 'positive_slacks', ',', 'w', ')']


All attention probs:

[0.006572912912815809, 0.007586076855659485, 0.024804623797535896, 0.009163903072476387, 0.009505162015557289, 0.006138181779533625, 0.01324745174497366, 0.0051300618797540665, 0.010089914314448833, 0.0070000276900827885, 0.0068441117182374, 0.008004211820662022, 0.00799341406673193, 0.01340379100292921, 0.006129798013716936, 0.005113072693347931, 0.004842488560825586, 0.009311026893556118, 0.004073591902852058, 0.005303989630192518, 0.004390159156173468, 0.008339878171682358, 0.0039056078530848026, 0.008434130810201168, 0.0037922707851976156, 0.002873423509299755, 0.002595123602077365, 0.0033100154250860214, 0.0024862356949597597, 0.0035307102371007204, 0.0024446609895676374, 0.00287913647480309, 0.0031133138108998537, 0.0022911159321665764, 0.0065337056294083595, 0.0017612528754398227, 0.002499254187569022, 0.002298518782481551, 0.003253478091210127, 0.0047036586329340935, 0.004196524154394865, 0.005719819571822882, 0.0036670982372015715, 0.0022523461375385523, 0.0017471358878538013, 0.0021984016057103872, 0.002118445932865143, 0.0021097855642437935, 0.0025770352222025394, 0.0055407267063856125, 0.0024817532394081354, 0.005894785281270742, 0.0019212285988032818, 0.0016442922642454505, 0.0028084067162126303, 0.0016620294190943241, 0.005223297979682684, 0.0015422170981764793, 0.006800848990678787, 0.0015392749337479472, 0.0016071255085989833, 0.001735079102218151, 0.001796284574083984, 0.0016474740114063025, 0.006182410754263401, 0.0020431512966752052, 0.0052578505128622055, 0.0023226896300911903, 0.004895838908851147, 0.002138451673090458, 0.0045899213291704655, 0.00241527846083045, 0.001526075298897922, 0.002521008485928178, 0.0013502017827704549, 0.0035451161675155163, 0.0009583124774508178, 0.0014623540919274092, 0.0010802161414176226, 0.0035105817951261997, 0.0013614121126011014, 0.006542889401316643, 0.0013319519348442554, 0.0062884497456252575, 0.0014044084819033742, 0.0020734043791890144, 0.0035925370175391436, 0.002285209484398365, 0.006825179327279329, 0.0016336239641532302, 0.0018813833594322205, 0.0010887860553339124, 0.004870777018368244, 0.001274033566005528, 0.0021315657068043947, 0.0013060806086286902, 0.001288965460844338, 0.001557548064738512, 0.0015268713468685746, 0.0038571387995034456, 0.0015501710586249828, 0.0026776515878736973, 0.0017703785561025143, 0.0021491453517228365, 0.0027944729663431644, 0.0009664332028478384, 0.0014762162463739514, 0.0013853467535227537, 0.00443553039804101, 0.0012626738753169775, 0.006806840188801289, 0.0016491598216816783, 0.006417084019631147, 0.0012069825315847993, 0.001656366977840662, 0.0014391776639968157, 0.0016916607273742557, 0.004161172080785036, 0.0013410595711320639, 0.0015858784317970276, 0.0017439392395317554, 0.002296540653333068, 0.001240939600393176, 0.004771821666508913, 0.0009833023650571704, 0.001576456823386252, 0.001313067157752812, 0.0020988667383790016, 0.0013711804058402777, 0.0022354729007929564, 0.0011435756459832191, 0.0009747760486789048, 0.001283486490137875, 0.0016736738616600633, 0.0015133116394281387, 0.0044763279147446156, 0.002468965481966734, 0.001083143288269639, 0.0018975877901539207, 0.0013067217078059912, 0.001685735653154552, 0.0011615901021286845, 0.0012680981308221817, 0.001369328354485333, 0.00797509215772152, 0.001054128515534103, 0.0009622110519558191, 0.0009879270801320672, 0.0015511345118284225, 0.0016709868796169758, 0.00386506668291986, 0.0016577495262026787, 0.0017402085941284895, 0.001875696238130331, 0.004402829799801111, 0.003095092950388789, 0.0016463124193251133, 0.0015385663136839867, 0.002240265253931284, 0.0010711124632507563, 0.0015771518228575587, 0.0014950028853490949, 0.0012786793522536755, 0.0014180559664964676, 0.0013161004753783345, 0.0011843051761388779, 0.0014103996800258756, 0.006489296909421682, 0.0009309813030995429, 0.0008324004011228681, 0.001099616289138794, 0.004138800781220198, 0.00099704519379884, 0.0018885144963860512, 0.001212280592881143, 0.0011743163922801614, 0.0009523218614049256, 0.0020728546660393476, 0.00483954232186079, 0.002192605985328555, 0.002502989722415805, 0.001507316599600017, 0.008689116686582565, 0.0014413006138056517, 0.0051635862328112125, 0.0014981043059378862, 0.002216032240539789, 0.002652418101206422, 0.0030259096529334784, 0.006473224144428968, 0.0027600890025496483, 0.007344422396272421, 0.0019089520210400224, 0.0022510222624987364, 0.0020282058976590633, 0.006017294246703386, 0.0017653177492320538, 0.005237531382590532, 0.001236483221873641, 0.005739217158406973, 0.0010140488157048821, 0.0019652394112199545, 0.007197917439043522, 0.0026989614125341177, 0.01259311381727457, 0.0011972658103331923, 0.005129506811499596, 0.0011686970246955752, 0.0019873713608831167, 0.00535700423642993, 0.002042424865067005, 0.003593226196244359, 0.000909829162992537, 0.0014329168479889631, 0.0009136720327660441, 0.001028786995448172, 0.00145749282091856, 0.004029217641800642, 0.001170427887700498, 0.007361825555562973, 0.0011037171352654696, 0.005649397615343332, 0.0012058429419994354, 0.0026051050517708063, 0.0015359380049631, 0.0017643161118030548, 0.001576797803863883, 0.0021530799567699432, 0.0040818811394274235, 0.0012785375583916903, 0.0009749820455908775, 0.0036120584700256586, 0.0007074028253555298, 0.001166650326922536, 0.0008202161407098174, 0.0011684084311127663, 0.0014619992580264807, 0.003448117757216096, 0.0012119192397221923, 0.006581415422260761, 0.0009727725991979241, 0.0010999758960679173, 0.00308857299387455, 0.0007528567221015692, 0.0013591565657407045, 0.0008333158330060542, 0.0015250765718519688, 0.0013025793014094234, 0.003998412285000086, 0.0014024850679561496, 0.005845545791089535, 0.0016680076951161027, 0.002078393241390586, 0.0030024400912225246, 0.00546856876462698, 0.0029882886447012424, 0.001984694739803672, 0.0009964433265849948, 0.001421621534973383, 0.0011100295232608914, 0.004365281201899052, 0.0006671135197393596, 0.0010176710784435272, 0.0007648779428564012, 0.0012284487020224333, 0.0012812259374186397, 0.0072273327969014645, 0.0011335074668750167, 0.004741893615573645, 0.0011567682959139347, 0.0012038227869197726, 0.0017801743233576417, 0.007476145401597023, 0.0011167185148224235, 0.0018113735131919384, 0.0007965837139636278, 0.001568041043356061, 0.001093096099793911, 0.001739310915581882, 0.0012186234816908836, 0.0011746376985684037, 0.00613610353320837, 0.0015194248408079147, 0.0015799824614077806, 0.0011547021567821503, 0.0016175342025235295, 0.002658276120200753, 0.01175532117486, 0.0031570603605359793, 0.006840681191533804, 0.001353633007965982, 0.0011862111277878284, 0.0010514885652810335, 0.0017686797073110938, 0.003375898813828826, 0.0017362036742269993, 0.0061638373881578445, 0.0017135385423898697, 0.004272411111742258, 0.0012585908407345414, 0.004042881540954113, 0.0007995076011866331, 0.0009893144015222788, 0.0018090575467795134, 0.003125168150290847, 0.0008106345194391906, 0.0015079008881002665, 0.0011467593722045422, 0.0012567004887387156, 0.0065297880209982395, 0.0012877329718321562, 0.0012487102067098022, 0.0014350389828905463, 0.005699888337403536, 0.0015381962293758988, 0.0015978990122675896, 0.0019809198565781116, 0.006768723949790001, 0.0020717927254736423, 0.0062752990052104, 0.0013880764599889517, 0.0015771702164784074, 0.001441329251974821, 0.0014836335321888328, 0.002143355319276452, 0.001257820171304047, 0.008348102681338787, 0.001298156101256609, 0.007575610652565956, 0.0013179973466321826, 0.008086051791906357, 0.001341533032245934]


Top-k source tokens:

['self', 'n_samples', 'Y', 'Y', 'w', 'w', 'X', 'X', ',', 'n_samples']


Top-k attention probs:

[0.024804623797535896, 0.01340379100292921, 0.01324745174497366, 0.01259311381727457, 0.01175532117486, 0.010089914314448833, 0.009505162015557289, 0.009311026893556118, 0.009163903072476387, 0.008689116686582565]
