
Original sample:

{"has_bug": true, "bug_kind": 1, "bug_kind_name": "VARIABLE_MISUSE", "source_tokens": ["#NEWLINE#", "def testRoundingError(", "self", ")", ":", "#NEWLINE#", "#INDENT#", "'Scaling might give us some rounding error.  Make sure that the encoder\\n    deals with it properly.\\n    '", "#NEWLINE#", "a", "=", "[", "(", "-", "1", ")", ",", "0", ",", "0", ",", "1", ",", "60", ",", "61", ",", "61", ",", "62", "]", "#NEWLINE#", "b", "=", "[", "(", "-", "0.999999", ")", ",", "(", "-", "1e-05", ")", ",", "1e-05", ",", "0.99998", ",", "60.00001", ",", "60.99999", ",", "61.00001", ",", "61.99998", "]", "#NEWLINE#", "self", ".", "assertEqual", "(", "self", ".", "simple", ".", "Encode", "(", "b", ")", ",", "self", ".", "simple", ".", "Encode", "(", "b", ")", ")"], "error_location": [68], "repair_targets": [9], "repair_candidates": [9, 2, 58, 62, 71, 32, 68, 77], "provenances": [{"datasetProvenance": {"datasetName": "ETHPy150Open", "filepath": "baz/app-sales-machine/lib/graphy/backends/google_chart_api/util_test.py", "license": "bsd-3-clause", "note": "license: bigquery_api"}}], "txt_file": "eval__VARIABLE_MISUSE__SStuB.txt-00001-of-00300", "js_count": 3736, "results": {"model": "transformer", "prob": {"loc": [[0.001609529834240675, 4.574557976866345e-08, 5.3552202672335625e-09, 1.2683472050412092e-09, 2.7876678743155026e-09, 1.7485222159052682e-09, 8.465289025316736e-10, 1.2167995500078632e-09, 3.404801718343009e-10, 7.784466049542971e-08, 1.8125453360440247e-09, 8.605571255593247e-10, 6.675874963946171e-09, 1.2115592973316325e-08, 3.13707374743899e-07, 2.729644066334913e-09, 3.8338372476687255e-09, 3.1690979085396975e-07, 9.310207715884644e-09, 3.3569881452422123e-07, 7.2652222016245105e-09, 3.927210343590559e-07, 5.137712477676359e-09, 9.818456447874269e-08, 5.7493245719797414e-09, 1.0396638572274242e-07, 7.633648380078739e-09, 1.1475261629811939e-07, 9.084670793413352e-09, 4.0400010448138346e-07, 5.2349493628867094e-09, 3.3228557683173676e-09, 7.568220894427213e-07, 2.0136587508545745e-08, 4.162720301792433e-08, 1.9433834097526415e-07, 3.7797701679664897e-07, 1.8455831423125346e-06, 1.2352650458069547e-07, 5.631773802861062e-08, 3.00103977224353e-07, 1.4212262158252997e-06, 2.5256749722757377e-06, 4.828450528293615e-07, 3.293056636266556e-07, 4.637526217265986e-06, 6.262075089580321e-07, 9.988947340389132e-07, 4.02207490424189e-07, 7.496918215110782e-07, 3.0589782795686915e-07, 5.313297606335254e-07, 2.1362851043704723e-07, 9.173501211989787e-07, 1.460066272329641e-07, 5.522784931599745e-07, 7.794099587954406e-08, 7.48418429452613e-08, 4.5289936245751505e-09, 5.515104817277461e-09, 4.998118585675115e-10, 1.1214948969495708e-08, 2.1591429799627804e-07, 6.229891269526888e-09, 8.234015691499508e-10, 4.6471440029449695e-09, 1.0434333397313367e-09, 1.212887070778379e-07, 0.6270568370819092, 4.264607511572649e-08, 4.277266540952951e-08, 8.714602154213935e-05, 1.489165790680147e-09, 5.077950837595324e-10, 1.5150420917819929e-09, 2.06478167896762e-10, 7.578736749280779e-09, 0.37122491002082825, 7.081114006268763e-08, 4.1864161914872966e-08]], "pointer": [[0.0, 0.0, 6.496884452644736e-08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9999850988388062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4254752386477776e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.592889979448955e-08, 0.0, 0.0, 0.0, 3.511718560389454e-08, 0.0, 0.0, 0.0, 0.0, 0.0, 2.103706009393136e-07, 0.0, 0.0, 8.90597036118379e-08, 0.0, 0.0, 0.0, 0.0, 0.0, 1.2897601209260756e-07, 0.0, 0.0]], "target": [0.9999850988388062]}, "loss": [0.46671807765960693, 1.4901272152201273e-05], "acc": [0.0, 1.0, 1.0, 1.0]}}


All source tokens:

['#NEWLINE#', 'def testRoundingError(', 'self', ')', ':', '#NEWLINE#', '#INDENT#', "'Scaling might give us some rounding error.  Make sure that the encoder\\n    deals with it properly.\\n    '", '#NEWLINE#', 'a', '=', '[', '(', '-', '1', ')', ',', '0', ',', '0', ',', '1', ',', '60', ',', '61', ',', '61', ',', '62', ']', '#NEWLINE#', 'b', '=', '[', '(', '-', '0.999999', ')', ',', '(', '-', '1e-05', ')', ',', '1e-05', ',', '0.99998', ',', '60.00001', ',', '60.99999', ',', '61.00001', ',', '61.99998', ']', '#NEWLINE#', 'self', '.', 'assertEqual', '(', 'self', '.', 'simple', '.', 'Encode', '(', 'b', ')', ',', 'self', '.', 'simple', '.', 'Encode', '(', 'b', ')', ')']


All attention probs:

[0.02607288584113121, 0.01625441201031208, 0.05774802342057228, 0.01620507426559925, 0.011865640059113503, 0.01313986536115408, 0.011362332850694656, 0.017915578559041023, 0.012304128147661686, 0.0871831402182579, 0.012138158082962036, 0.009849765338003635, 0.011785285547375679, 0.009148957207798958, 0.01401585154235363, 0.0071452041156589985, 0.00795816257596016, 0.010176369920372963, 0.007850457914173603, 0.01026601530611515, 0.007894306443631649, 0.011204767040908337, 0.007462614681571722, 0.01013031043112278, 0.007368587888777256, 0.010477127507328987, 0.006429594941437244, 0.010328895412385464, 0.0061693997122347355, 0.014922963455319405, 0.00638522207736969, 0.009220391511917114, 0.03839104250073433, 0.008727997541427612, 0.006252949591726065, 0.007279504556208849, 0.007177273277193308, 0.011282561346888542, 0.006331023760139942, 0.007014824077486992, 0.007874427363276482, 0.007219833321869373, 0.011880932375788689, 0.006168074440211058, 0.006340875290334225, 0.00790573749691248, 0.006755294278264046, 0.005410382058471441, 0.00607354287058115, 0.007375975605100393, 0.006065863184630871, 0.006758658215403557, 0.006057651713490486, 0.00834473967552185, 0.006006095092743635, 0.007813983596861362, 0.004974264185875654, 0.007703194860368967, 0.023580431938171387, 0.004882914945483208, 0.0062448084354400635, 0.0069756587035954, 0.021269027143716812, 0.00602696044370532, 0.008976126089692116, 0.00918926578015089, 0.009323406033217907, 0.010536406189203262, 0.05080597847700119, 0.006935757119208574, 0.008827210403978825, 0.024276362732052803, 0.005933298729360104, 0.011712291277945042, 0.005742361303418875, 0.009090215899050236, 0.008733762428164482, 0.050141237676143646, 0.006136064883321524, 0.007094256114214659]


Top-k source tokens:

['a', 'self', 'b', 'b', 'b', '#NEWLINE#', 'self', 'self', 'self', "'Scaling might give us some rounding error.  Make sure that the encoder\\n    deals with it properly.\\n    '"]


Top-k attention probs:

[0.0871831402182579, 0.05774802342057228, 0.05080597847700119, 0.050141237676143646, 0.03839104250073433, 0.02607288584113121, 0.024276362732052803, 0.023580431938171387, 0.021269027143716812, 0.017915578559041023]
