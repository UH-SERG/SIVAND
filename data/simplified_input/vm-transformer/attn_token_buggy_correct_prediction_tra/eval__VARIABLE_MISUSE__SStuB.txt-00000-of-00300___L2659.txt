
Original sample:

{"has_bug": true, "bug_kind": 1, "bug_kind_name": "VARIABLE_MISUSE", "source_tokens": ["#NEWLINE#", "def applyFilters(", "self", ",", "endpoint", ")", ":", "#NEWLINE#", "#INDENT#", "'Apply filter functions to an endpoint until one of them\\n        returns non-None.'", "#NEWLINE#", "for", "filter_function", "in", "endpoint", ".", "filter_functions", ":", "#NEWLINE#", "#INDENT#", "e", "=", "filter_function", "(", "endpoint", ")", "#NEWLINE#", "if", "(", "e", "is not", "None", ")", ":", "#NEWLINE#", "#INDENT#", "return", "e", "#NEWLINE#", "#UNINDENT#", "#UNINDENT#", "return", "None"], "error_location": [14], "repair_targets": [2], "repair_candidates": [4, 14, 24, 20, 29, 37, 12, 22, 2], "provenances": [{"datasetProvenance": {"datasetName": "ETHPy150Open", "filepath": "CollabQ/CollabQ/openid/yadis/filters.py", "license": "apache-2.0", "note": "license: bigquery_api"}}], "txt_file": "eval__VARIABLE_MISUSE__SStuB.txt-00000-of-00300", "js_count": 2659, "results": {"model": "transformer", "prob": {"loc": [[0.1552426666021347, 2.5968056434066966e-06, 2.6244658783980412e-06, 6.294208265700263e-09, 9.369197186970268e-07, 9.505067843917914e-09, 2.0304275594185128e-08, 2.2565847856981236e-08, 1.3890593564269693e-08, 8.569277731851344e-09, 2.0838811565226933e-08, 1.9713052523684382e-08, 2.1343125808925834e-06, 3.803653392253636e-09, 0.8193225860595703, 5.382433414524712e-07, 2.2442314673298824e-08, 8.092246162050287e-08, 2.3260371406763625e-08, 5.374969358484805e-09, 2.0045661131007364e-07, 6.749338421485618e-09, 1.584528581588529e-05, 2.0413656898199406e-07, 0.02300531044602394, 7.125137102548251e-08, 3.093682821031507e-08, 2.047812586170039e-08, 7.76885578090969e-09, 0.0008438119548372924, 5.5983687019534045e-08, 1.88289561720012e-08, 1.2437634033801714e-08, 3.743642551512494e-08, 4.591428393041497e-08, 1.562273865829411e-08, 2.1146384643344618e-09, 0.001559077063575387, 9.74772547124303e-08, 9.79128245148786e-08, 8.634252424144506e-08, 1.0988448373439041e-08, 5.060298349235381e-07]], "pointer": [[0.0, 0.0, 0.986423909664154, 0.0, 0.002028948161751032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011443824507296085, 0.0, 1.9186358258593827e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 3.653802423286834e-06, 0.0, 2.308044713572599e-06, 0.0, 7.638835813850164e-05, 0.0, 0.0, 0.0, 0.0, 3.774749472995609e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.419906993760378e-06, 0.0, 0.0, 0.0, 0.0, 0.0]], "target": [0.986423909664154]}, "loss": [0.19927720725536346, 0.01366908848285675], "acc": [0.0, 1.0, 1.0, 1.0]}}


All source tokens:

['#NEWLINE#', 'def applyFilters(', 'self', ',', 'endpoint', ')', ':', '#NEWLINE#', '#INDENT#', "'Apply filter functions to an endpoint until one of them\\n        returns non-None.'", '#NEWLINE#', 'for', 'filter_function', 'in', 'endpoint', '.', 'filter_functions', ':', '#NEWLINE#', '#INDENT#', 'e', '=', 'filter_function', '(', 'endpoint', ')', '#NEWLINE#', 'if', '(', 'e', 'is not', 'None', ')', ':', '#NEWLINE#', '#INDENT#', 'return', 'e', '#NEWLINE#', '#UNINDENT#', '#UNINDENT#', 'return', 'None']


All attention probs:

[0.024104049429297447, 0.017092503607273102, 0.07700861990451813, 0.02631649561226368, 0.03844873234629631, 0.020452672615647316, 0.017374161630868912, 0.018447494134306908, 0.017936689779162407, 0.024742694571614265, 0.022385308519005775, 0.021478578448295593, 0.05131717398762703, 0.020561154931783676, 0.04702375829219818, 0.010670251213014126, 0.012593193911015987, 0.010707959532737732, 0.015692533925175667, 0.014727877452969551, 0.0443427674472332, 0.01699027046561241, 0.02040654793381691, 0.013030615635216236, 0.044236134737730026, 0.008962366729974747, 0.013979891315102577, 0.015374775975942612, 0.010658211074769497, 0.03882618248462677, 0.012831749394536018, 0.014034716412425041, 0.015780726447701454, 0.01724887266755104, 0.018268290907144547, 0.018374208360910416, 0.021769674494862556, 0.03925061598420143, 0.018959281966090202, 0.018225954845547676, 0.017531918361783028, 0.024440206587314606, 0.02739410661160946]


Top-k source tokens:

['self', 'filter_function', 'endpoint', 'e', 'endpoint', 'e', 'e', 'endpoint', 'None', ',']


Top-k attention probs:

[0.07700861990451813, 0.05131717398762703, 0.04702375829219818, 0.0443427674472332, 0.044236134737730026, 0.03925061598420143, 0.03882618248462677, 0.03844873234629631, 0.02739410661160946, 0.02631649561226368]
