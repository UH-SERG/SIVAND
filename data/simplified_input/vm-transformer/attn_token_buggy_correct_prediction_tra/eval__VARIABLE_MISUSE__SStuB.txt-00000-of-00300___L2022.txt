
Original sample:

{"has_bug": true, "bug_kind": 1, "bug_kind_name": "VARIABLE_MISUSE", "source_tokens": ["#NEWLINE#", "def line_tokenize(", "text", ",", "blanklines", "=", "'discard'", ")", ":", "#NEWLINE#", "#INDENT#", "return", "LineTokenizer", "(", "blanklines", ")", ".", "tokenize", "(", "blanklines", ")"], "error_location": [19], "repair_targets": [2], "repair_candidates": [4, 14, 19, 2], "provenances": [{"datasetProvenance": {"datasetName": "ETHPy150Open", "filepath": "nltk/nltk/nltk/tokenize/simple.py", "license": "apache-2.0", "note": "license: manual_eval"}}], "txt_file": "eval__VARIABLE_MISUSE__SStuB.txt-00000-of-00300", "js_count": 2022, "results": {"model": "transformer", "prob": {"loc": [[0.0001983150141313672, 4.0278131052673416e-08, 9.842179338193091e-08, 1.2439634211602879e-08, 6.219438120069753e-08, 7.1846515403706235e-09, 7.275892954794472e-08, 1.431509133453801e-08, 1.786727921171405e-08, 1.9254501992804762e-08, 2.0888567320298534e-08, 6.528171891950763e-10, 1.3639338269921808e-10, 2.87004781052147e-10, 0.0022646968718618155, 8.019267028203103e-08, 1.6956974491222354e-08, 1.3863113434986474e-10, 2.1072914524467024e-09, 0.997515082359314, 2.1559486413025297e-05]], "pointer": [[0.0, 0.0, 0.9999996423721313, 0.0, 3.6731725572280993e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4540000314866575e-08, 0.0, 0.0, 0.0, 0.0, 1.0401735028864323e-09, 0.0]], "target": [0.9999996423721313]}, "loss": [0.002488137688487768, 3.576279254957626e-07], "acc": [0.0, 1.0, 1.0, 1.0]}}


All source tokens:

['#NEWLINE#', 'def line_tokenize(', 'text', ',', 'blanklines', '=', "'discard'", ')', ':', '#NEWLINE#', '#INDENT#', 'return', 'LineTokenizer', '(', 'blanklines', ')', '.', 'tokenize', '(', 'blanklines', ')']


All attention probs:

[0.05163604021072388, 0.0305867251008749, 0.09392502158880234, 0.03934237360954285, 0.10658332705497742, 0.03781183063983917, 0.057319942861795425, 0.02847219444811344, 0.02819778583943844, 0.03575289994478226, 0.03738946095108986, 0.051186978816986084, 0.04239571467041969, 0.028723707422614098, 0.07584656774997711, 0.023760758340358734, 0.017496131360530853, 0.025310559198260307, 0.025703052058815956, 0.11469518393278122, 0.047863736748695374]


Top-k source tokens:

['blanklines', 'blanklines', 'text', 'blanklines', "'discard'", '#NEWLINE#', 'return', ')', 'LineTokenizer', ',']


Top-k attention probs:

[0.11469518393278122, 0.10658332705497742, 0.09392502158880234, 0.07584656774997711, 0.057319942861795425, 0.05163604021072388, 0.051186978816986084, 0.047863736748695374, 0.04239571467041969, 0.03934237360954285]
