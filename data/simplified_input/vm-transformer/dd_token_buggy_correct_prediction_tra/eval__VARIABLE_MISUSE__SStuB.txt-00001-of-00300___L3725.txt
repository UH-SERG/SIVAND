
Original sample:

{"has_bug": true, "bug_kind": 1, "bug_kind_name": "VARIABLE_MISUSE", "source_tokens": ["#NEWLINE#", "def create(", "kernel", ")", ":", "#NEWLINE#", "#INDENT#", "result", "=", "Tangible", "(", ")", "#NEWLINE#", "result", ".", "template", "=", "'object/tangible/veteran_reward/shared_frn_couch_falcon_section_s01.iff'", "#NEWLINE#", "result", ".", "attribute_template_id", "=", "(", "-", "1", ")", "#NEWLINE#", "result", ".", "stfName", "(", "'frn_n'", ",", "'vet_couch_falcon_section_s01'", ")", "#NEWLINE#", "return", "kernel"], "error_location": [38], "repair_targets": [7, 13, 19, 28], "repair_candidates": [7, 13, 19, 28, 2, 38], "provenances": [{"datasetProvenance": {"datasetName": "ETHPy150Open", "filepath": "anhstudios/swganh/data/scripts/templates/object/tangible/veteran_reward/shared_frn_couch_falcon_section_s01.py", "license": "mit", "note": "license: bigquery_api"}}], "txt_file": "eval__VARIABLE_MISUSE__SStuB.txt-00001-of-00300", "js_count": 3725, "results": {"model": "transformer", "prob": {"loc": [[8.67415565153351e-06, 7.322086270633577e-10, 4.657338070757078e-09, 4.851754761836524e-11, 4.9343102520582605e-11, 3.506158210986321e-11, 4.035578468619683e-11, 1.3809926813213025e-10, 1.2448726771641105e-10, 6.999985313616008e-11, 3.4809521931578047e-10, 1.9805251882942798e-10, 7.952413033640582e-11, 2.3477231270163657e-10, 2.522396874704569e-11, 4.205807143525808e-12, 3.220513439261552e-11, 6.589918610799828e-10, 5.332456143314346e-10, 2.694114042967044e-09, 3.503310141983462e-11, 1.4089093607061454e-11, 1.3115514230221947e-10, 1.2807008786808183e-09, 2.48184778284255e-10, 8.456254363409244e-09, 1.0034348907339563e-09, 2.6876201264514066e-10, 8.241288207422315e-10, 8.550950225671983e-11, 2.6008334375049458e-11, 3.4485839184306144e-10, 1.0122219507024965e-08, 1.1198587612781807e-09, 1.885522493694225e-08, 2.8133440022060086e-09, 5.710449446638677e-09, 4.461755054308014e-07, 0.9999908208847046]], "pointer": [[0.0, 0.0, 1.799824822512619e-08, 0.0, 0.0, 0.0, 0.0, 0.00910499319434166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01235774252563715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02504078485071659, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9534964561462402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.04497235706458e-09]], "target": [1.0]}, "loss": [9.179073458653875e-06, -0.0], "acc": [0.0, 1.0, 1.0, 1.0]}}


Trace of simplified code(s):

{"result": {"time": "2021-02-11 12:04:40.582238", "n_pass": [1, 1, 1], "n_token": 39, "loss": [9.179073458653875e-06, -0.0], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def create(", "kernel", ")", ":", "#NEWLINE#", "#INDENT#", "result", "=", "Tangible", "(", ")", "#NEWLINE#", "result", ".", "template", "=", "'object/tangible/veteran_reward/shared_frn_couch_falcon_section_s01.iff'", "#NEWLINE#", "result", ".", "attribute_template_id", "=", "(", "-", "1", ")", "#NEWLINE#", "result", ".", "stfName", "(", "'frn_n'", ",", "'vet_couch_falcon_section_s01'", ")", "#NEWLINE#", "return", "kernel"]}}
{"position": {"error_location": 38, "repair_targets": [7, 13, 19, 28], "repair_candidates": [7, 13, 19, 28, 2, 38]}}
{"prediction": {"error_location": 0.9999908208847046, "repair_targets": [0.00910499319434166, 0.01235774252563715, 0.02504078485071659, 0.9534964561462402], "repair_candidates": [1.799824822512619e-08, 0.00910499319434166, 0.01235774252563715, 0.02504078485071659, 0.9534964561462402, 4.04497235706458e-09], "target_probs": 1.0}}


{"result": {"time": "2021-02-11 12:04:40.638072", "n_pass": [23, 2, 2], "n_token": 34, "loss": [9.65590606938349e-06, 5.960464477539063e-08], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def create(", "kernel", ")", ":", "#NEWLINE#", "#INDENT#", "result", "=", "Tangible", "(", ")", "#NEWLINE#", "result", "result", ".", "attribute_template_id", "=", "(", "-", "1", ")", "#NEWLINE#", "result", ".", "stfName", "(", "'frn_n'", ",", "'vet_couch_falcon_section_s01'", ")", "#NEWLINE#", "return", "kernel"]}}
{"position": {"error_location": 33, "repair_targets": [7, 13, 14, 23], "repair_candidates": [7, 13, 14, 23, 2, 33]}}
{"prediction": {"error_location": 0.9999903440475464, "repair_targets": [0.012599981389939785, 0.03747819736599922, 0.02523719146847725, 0.9246845841407776], "repair_candidates": [3.642182022645102e-08, 0.012599981389939785, 0.03747819736599922, 0.02523719146847725, 0.9246845841407776, 4.049822255325353e-09], "target_probs": 0.9999999403953552}}


{"result": {"time": "2021-02-11 12:04:40.692868", "n_pass": [26, 3, 3], "n_token": 29, "loss": [0.0003003622987307608, 8.344653679159819e-07], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def create(", "kernel", ")", ":", "#NEWLINE#", "#INDENT#", "result", "=", "Tangible", "(", ")", "#NEWLINE#", "result", "result", ".", "attribute_template_id", "=", "(", "-", "1", ")", "#NEWLINE#", "result", "'vet_couch_falcon_section_s01'", ")", "#NEWLINE#", "return", "kernel"]}}
{"position": {"error_location": 28, "repair_targets": [7, 13, 14, 23], "repair_candidates": [7, 13, 14, 23, 2, 28]}}
{"prediction": {"error_location": 0.999699592590332, "repair_targets": [0.052023377269506454, 0.12424449622631073, 0.10003162920475006, 0.7236996293067932], "repair_candidates": [7.57357213387877e-07, 0.052023377269506454, 0.12424449622631073, 0.10003162920475006, 0.7236996293067932, 8.66346852035349e-08], "target_probs": 0.9999991655349731}}


{"result": {"time": "2021-02-11 12:04:40.805845", "n_pass": [49, 5, 4], "n_token": 27, "loss": [0.0003743662964552641, 1.7881409348774469e-06], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def create(", "kernel", ")", "#INDENT#", "result", "=", "Tangible", "(", ")", "#NEWLINE#", "result", "result", ".", "attribute_template_id", "=", "(", "-", "1", ")", "#NEWLINE#", "result", "'vet_couch_falcon_section_s01'", ")", "#NEWLINE#", "return", "kernel"]}}
{"position": {"error_location": 26, "repair_targets": [5, 11, 12, 21], "repair_candidates": [5, 11, 12, 21, 2, 26]}}
{"prediction": {"error_location": 0.9996256828308105, "repair_targets": [0.02488050051033497, 0.25421780347824097, 0.21333272755146027, 0.5075671672821045], "repair_candidates": [1.456154564039025e-06, 0.02488050051033497, 0.25421780347824097, 0.21333272755146027, 0.5075671672821045, 2.9927616651548306e-07], "target_probs": 0.9999982118606567}}


{"result": {"time": "2021-02-11 12:04:40.860801", "n_pass": [51, 6, 5], "n_token": 25, "loss": [0.0008816407644189894, 8.73842291184701e-05], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def create(", "kernel", ")", "#INDENT#", "result", "(", ")", "#NEWLINE#", "result", "result", ".", "attribute_template_id", "=", "(", "-", "1", ")", "#NEWLINE#", "result", "'vet_couch_falcon_section_s01'", ")", "#NEWLINE#", "return", "kernel"]}}
{"position": {"error_location": 24, "repair_targets": [5, 9, 10, 19], "repair_candidates": [5, 9, 10, 19, 2, 24]}}
{"prediction": {"error_location": 0.9991187453269958, "repair_targets": [0.006436663679778576, 0.6498503088951111, 0.15777140855789185, 0.1858542412519455], "repair_candidates": [8.294964209198952e-05, 0.006436663679778576, 0.6498503088951111, 0.15777140855789185, 0.1858542412519455, 4.380417067295639e-06], "target_probs": 0.9999126195907593}}


{"result": {"time": "2021-02-11 12:04:40.915912", "n_pass": [52, 7, 6], "n_token": 23, "loss": [0.003447662340477109, 0.00011581853323150426], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def create(", "kernel", ")", "#INDENT#", "result", "#NEWLINE#", "result", "result", ".", "attribute_template_id", "=", "(", "-", "1", ")", "#NEWLINE#", "result", "'vet_couch_falcon_section_s01'", ")", "#NEWLINE#", "return", "kernel"]}}
{"position": {"error_location": 22, "repair_targets": [5, 7, 8, 17], "repair_candidates": [5, 7, 8, 17, 2, 22]}}
{"prediction": {"error_location": 0.9965583682060242, "repair_targets": [0.00450842035934329, 0.4616123139858246, 0.4097108542919159, 0.12405256181955338], "repair_candidates": [0.00010170477617066354, 0.00450842035934329, 0.4616123139858246, 0.4097108542919159, 0.12405256181955338, 1.4240607924875803e-05], "target_probs": 0.9998841881752014}}


{"result": {"time": "2021-02-11 12:04:40.971163", "n_pass": [55, 8, 7], "n_token": 20, "loss": [0.01288787554949522, 0.0008669079979881644], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def create(", "kernel", ")", "#INDENT#", "result", "#NEWLINE#", "result", "result", ".", "attribute_template_id", "1", ")", "#NEWLINE#", "result", "'vet_couch_falcon_section_s01'", ")", "#NEWLINE#", "return", "kernel"]}}
{"position": {"error_location": 19, "repair_targets": [5, 7, 8, 14], "repair_candidates": [5, 7, 8, 14, 2, 19]}}
{"prediction": {"error_location": 0.9871947169303894, "repair_targets": [0.010016152635216713, 0.40790218114852905, 0.3472530245780945, 0.23396211862564087], "repair_candidates": [0.000800011504907161, 0.010016152635216713, 0.40790218114852905, 0.3472530245780945, 0.23396211862564087, 6.651086005149409e-05], "target_probs": 0.9991334676742554}}


{"result": {"time": "2021-02-11 12:04:41.025821", "n_pass": [56, 9, 8], "n_token": 17, "loss": [0.026369880884885788, 0.0006643952219747007], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["#NEWLINE#", "def create(", "kernel", ")", "#INDENT#", "result", "#NEWLINE#", "result", "result", ".", "attribute_template_id", "result", "'vet_couch_falcon_section_s01'", ")", "#NEWLINE#", "return", "kernel"]}}
{"position": {"error_location": 16, "repair_targets": [5, 7, 8, 11], "repair_candidates": [5, 7, 8, 11, 2, 16]}}
{"prediction": {"error_location": 0.9739747643470764, "repair_targets": [0.02618550881743431, 0.5870858430862427, 0.3501003682613373, 0.03596410155296326], "repair_candidates": [0.0005996663821861148, 0.02618550881743431, 0.5870858430862427, 0.3501003682613373, 0.03596410155296326, 6.462410237872973e-05], "target_probs": 0.9993358254432678}}


{"result": {"time": "2021-02-11 12:04:41.083720", "n_pass": [59, 10, 9], "n_token": 15, "loss": [0.0020468730945140123, 0.0007113363244570792], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["kernel", ")", "#INDENT#", "result", "#NEWLINE#", "result", "result", ".", "attribute_template_id", "result", "'vet_couch_falcon_section_s01'", ")", "#NEWLINE#", "return", "kernel"]}}
{"position": {"error_location": 14, "repair_targets": [3, 5, 6, 9], "repair_candidates": [3, 5, 6, 9, 0, 14]}}
{"prediction": {"error_location": 0.9979552030563354, "repair_targets": [0.017044680193066597, 0.23411640524864197, 0.4363057315349579, 0.3118221163749695], "repair_candidates": [0.0005545319872908294, 0.017044680193066597, 0.23411640524864197, 0.4363057315349579, 0.3118221163749695, 0.00015651373541913927], "target_probs": 0.9992889165878296}}


{"result": {"time": "2021-02-11 12:04:41.138687", "n_pass": [79, 11, 10], "n_token": 14, "loss": [0.013281917199492455, 0.0007766520138829947], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["kernel", "#INDENT#", "result", "#NEWLINE#", "result", "result", ".", "attribute_template_id", "result", "'vet_couch_falcon_section_s01'", ")", "#NEWLINE#", "return", "kernel"]}}
{"position": {"error_location": 13, "repair_targets": [2, 4, 5, 8], "repair_candidates": [2, 4, 5, 8, 0, 13]}}
{"prediction": {"error_location": 0.9868059158325195, "repair_targets": [0.029219022020697594, 0.04743611067533493, 0.5519376397132874, 0.3706308603286743], "repair_candidates": [0.00021873846708331257, 0.029219022020697594, 0.04743611067533493, 0.5519376397132874, 0.3706308603286743, 0.0005576509283855557], "target_probs": 0.9992236495018005}}


{"result": {"time": "2021-02-11 12:04:41.193041", "n_pass": [80, 12, 11], "n_token": 13, "loss": [0.008004019036889076, 0.0008988246554508805], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["kernel", "result", "#NEWLINE#", "result", "result", ".", "attribute_template_id", "result", "'vet_couch_falcon_section_s01'", ")", "#NEWLINE#", "return", "kernel"]}}
{"position": {"error_location": 12, "repair_targets": [1, 3, 4, 7], "repair_candidates": [1, 3, 4, 7, 0, 12]}}
{"prediction": {"error_location": 0.9920280575752258, "repair_targets": [0.021212313324213028, 0.06849433481693268, 0.16083432734012604, 0.7485606074333191], "repair_candidates": [0.0005045782309025526, 0.021212313324213028, 0.06849433481693268, 0.16083432734012604, 0.7485606074333191, 0.0003937619330827147], "target_probs": 0.9991015791893005}}


{"result": {"time": "2021-02-11 12:04:41.246899", "n_pass": [82, 13, 12], "n_token": 12, "loss": [0.0017578639090061188, 0.015796858817338943], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["kernel", "result", "result", "result", ".", "attribute_template_id", "result", "'vet_couch_falcon_section_s01'", ")", "#NEWLINE#", "return", "kernel"]}}
{"position": {"error_location": 11, "repair_targets": [1, 2, 3, 6], "repair_candidates": [1, 2, 3, 6, 0, 11]}}
{"prediction": {"error_location": 0.9982436895370483, "repair_targets": [0.034410037100315094, 0.11068762838840485, 0.12133336067199707, 0.7178962230682373], "repair_candidates": [0.015640513971447945, 0.034410037100315094, 0.11068762838840485, 0.12133336067199707, 0.7178962230682373, 3.222289524273947e-05], "target_probs": 0.9843272566795349}}


{"result": {"time": "2021-02-11 12:04:41.301753", "n_pass": [85, 14, 13], "n_token": 11, "loss": [0.07724703103303909, 0.012389984913170338], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["kernel", "result", "result", "result", "attribute_template_id", "result", "'vet_couch_falcon_section_s01'", ")", "#NEWLINE#", "return", "kernel"]}}
{"position": {"error_location": 10, "repair_targets": [1, 2, 3, 5], "repair_candidates": [1, 2, 3, 5, 0, 10]}}
{"prediction": {"error_location": 0.9256611466407776, "repair_targets": [0.020240483805537224, 0.062105946242809296, 0.17867088317871094, 0.7266691327095032], "repair_candidates": [0.012085267342627048, 0.020240483805537224, 0.062105946242809296, 0.17867088317871094, 0.7266691327095032, 0.0002282618806930259], "target_probs": 0.9876864552497864}}


{"result": {"time": "2021-02-11 12:04:41.413955", "n_pass": [88, 16, 14], "n_token": 9, "loss": [0.3195895254611969, 0.19316861033439636], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["kernel", "result", "result", "result", "attribute_template_id", "result", "'vet_couch_falcon_section_s01'", "return", "kernel"]}}
{"position": {"error_location": 8, "repair_targets": [1, 2, 3, 5], "repair_candidates": [1, 2, 3, 5, 0, 8]}}
{"prediction": {"error_location": 0.7264471650123596, "repair_targets": [0.28510671854019165, 0.4177427887916565, 0.08010745048522949, 0.04138600826263428], "repair_candidates": [0.17249760031700134, 0.28510671854019165, 0.4177427887916565, 0.08010745048522949, 0.04138600826263428, 0.0031594152096658945], "target_probs": 0.8243429660797119}}


{"result": {"time": "2021-02-11 12:04:41.468552", "n_pass": [94, 17, 15], "n_token": 8, "loss": [0.4962685704231262, 0.04672961309552193], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["kernel", "result", "result", "result", "result", "'vet_couch_falcon_section_s01'", "return", "kernel"]}}
{"position": {"error_location": 7, "repair_targets": [1, 2, 3, 4], "repair_candidates": [1, 2, 3, 4, 0, 7]}}
{"prediction": {"error_location": 0.608798086643219, "repair_targets": [0.7420414090156555, 0.17325055599212646, 0.01942949928343296, 0.019623933359980583], "repair_candidates": [0.03931613638997078, 0.7420414090156555, 0.17325055599212646, 0.01942949928343296, 0.019623933359980583, 0.006338499020785093], "target_probs": 0.9543454051017761}}


{"result": {"time": "2021-02-11 12:04:41.577498", "n_pass": [106, 19, 16], "n_token": 7, "loss": [0.49956852197647095, 0.07720460742712021], "accuracy": [0.0, 1.0, 1.0, 1.0]}}
{"sample": {"has_bug": true, "source_tokens": ["kernel", "result", "result", "result", "result", "'vet_couch_falcon_section_s01'", "kernel"]}}
{"position": {"error_location": 6, "repair_targets": [1, 2, 3, 4], "repair_candidates": [1, 2, 3, 4, 0, 6]}}
{"prediction": {"error_location": 0.6067924499511719, "repair_targets": [0.5812246203422546, 0.2676287889480591, 0.04547439515590668, 0.031372617930173874], "repair_candidates": [0.06965462118387222, 0.5812246203422546, 0.2676287889480591, 0.04547439515590668, 0.031372617930173874, 0.004644974134862423], "target_probs": 0.9257004261016846}}




Minimal simplified tokens:

['kernel', 'result', 'result', 'result', 'result', "'vet_couch_falcon_section_s01'", 'kernel']
